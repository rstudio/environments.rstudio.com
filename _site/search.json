{
  "articles": [
    {
      "path": "collaborate.html",
      "title": "Team Collaboration",
      "description": "Easily Work Together\n",
      "author": [],
      "contents": "\nA common challenge on teams is sharing and running code. If you’ve sat down to run a colleague’s code, only to spend hours installing and updating packages, you’re familiar with the pain points. Luckily, adopting any of the strategies for creating a reproducible environment will result in easier team collaboration.\nHere, we’ll compare the Shared Baseline and the Snapshot and Restore strategies, with a special emphasis on how the two strategies can be used in collaborative settings. Before diving in to reproducible environments, it is critically important that teams master version control.\nStrategy Recap\nShared Baseline: Administrators manage multiple version of R on a shared server. Each version of R is associated with a frozen repository, so that all users accessing the same R installation access the same packages. The frozen repository prevents users or admins from breaking packages when they add new packages, by preventing “side-affect upgrades”.\nSnapshot and Restore: Using a tool like the renv package, users maintain an isolated project library and explicitly record the library’s content.\nEach of these strategies is easily adapted for teams wishing to collaborate on shared code.\nShared Baseline for Collaboration\nTeams wishing to use the shared baseline strategy for collaboration would follow these steps:\nRecord in your project code the version of R being used for the project.\nShare your project code using a version control tool like Git, or using RStudio Workbench’s project sharing.\nWhen the collaborator clones or opens the shared project, they should start the RStudio session with the noted version of R. If the admin has installed packages into the system library, the collaborator will be ready to run the code immediately. If not, the collaborator can install the necessary packages. The installation will automatically include the correct package versions because the R installation is tied to a frozen repository.\nSnapshot and Restore for Collaboration\nThe snapshot and restore strategy is easily adapted for collaboration using a tool like the renv package:\nThe developer creates a renv.lock file using renv::snapshot(). The lock file is committed alongside the application code into a version control system like Git.\nThe collaborator clones the Git repository into a new project. The renv.lock file is included.\nThe collaborator can use renv::restore() to recreate the necessary package environment for the project.\nFor more details, refer to the renv vignette on collaboration.\nComparison\nThe shared baseline strategy requires initial work to create a shared development server, a frozen repository, and multiple R installations. Once this upfront work is complete, day to day collaboration is straightforward. This strategy is best suited for a team with strong R administrators and can help teams that need to on board new R users rapidly.\nIn contrast, the snapshot and restore strategy has minimal initial work, but requires vigilance during day to day development and collaboration. This strategy is best suited for power R users or cases where a shared development server is not possible.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:10+00:00"
    },
    {
      "path": "deploy.html",
      "title": "Production Deployment",
      "description": "Safely Deploy R to Production\n",
      "author": [],
      "contents": "\n\nContents\nDevelopment to Production\nExample: RStudio Connect\nExample: renv and Docker\n\nTesting and Staging Environments\nExample: RStudio Connect with Git, Jenkins, and Chef\n\nAcceptable Differences\nR Patch Version\nR Package Source\n\nEnvironment Upgrades\n\nData products built in R, such as dashboards, web applications, reports, and APIs, are increasingly deployed to production. While specific definitions of production can vary, everyone agrees that production content should be stable. Most production systems use a variation of the Snapshot and Restore strategy. Here, we focuse on examples of production systems that apply the snapshot and restore strategy. This page also describes staging environments, acceptable differences between development and production environments, and strategies for upgrading production environments.\nThis page focuses on reproducible environments for production content. There are other important concerns for placing R code in production:\nversion control\nunit testing and integration testing\nperformance profiling and load testing\ndata security\nDevelopment to Production\nProduction systems come in different shapes and sizes. Some organizations store code in Git and use continuous integration tools like Jenkins to deploy content. Other organizations might use containers and an orchestration tool like Kubernetes. Or, you may use infrastructure-as-code tooling like Chef or Puppet to deploy products onto physical, virtual, or cloud servers.\nRegardless of the specific implementation, there are three basic steps required to deploy R environments to production:\nIn the development environment, the data product’s dependencies should be snapshotted.\nIn production, an isolated environment should be created for the data product.\nIn the isolated environment, the dependencies should be restored exactly, with matching versions.\n\nA simple checklist:\n- [ ] snapshot\n- [ ] isolate\n- [ ] restore\nThese steps are the heart of the “snapshot and restore” strategy for reproducing environments. The following two examples showcase implementations of this strategy in production systems. These examples are not exhaustive, and you can certainly design other processes. All implementations should meet the key requirements of snapshot, isolate, and restore.\nExample: RStudio Connect\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#fpchncnfoz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fpchncnfoz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fpchncnfoz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fpchncnfoz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fpchncnfoz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fpchncnfoz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fpchncnfoz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fpchncnfoz .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fpchncnfoz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fpchncnfoz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fpchncnfoz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fpchncnfoz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fpchncnfoz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#fpchncnfoz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fpchncnfoz .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fpchncnfoz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fpchncnfoz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fpchncnfoz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fpchncnfoz .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#fpchncnfoz .gt_left {\n  text-align: left;\n}\n\n#fpchncnfoz .gt_center {\n  text-align: center;\n}\n\n#fpchncnfoz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fpchncnfoz .gt_font_normal {\n  font-weight: normal;\n}\n\n#fpchncnfoz .gt_font_bold {\n  font-weight: bold;\n}\n\n#fpchncnfoz .gt_font_italic {\n  font-style: italic;\n}\n\n#fpchncnfoz .gt_super {\n  font-size: 65%;\n}\n\n#fpchncnfoz .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\n\n      RStudio Connect Implementation\n    Snapshot\nManifest file is created during publicationIsolate\nRStudio Connect creates an isolated package library for each piece of contentRestore\nConnect installs the packages listed in the manifest into the isolated library\n\nRStudio Connect is a publishing platform for data products, that automatically implements the snapshot and restore strategy when users publish content. If you’re using RStudio Connect, you don’t need to manually manage this process. Here is what happens when a data product is deployed:\nThe version of R in use, the current repository, and the list of R packages are recorded in a manifest file. Users typically don’t see this file, but if you’d like to explore it, run rsconnect::writeManifest() from within your project’s working directory in the development environment. Here is a sample from a manifest file:\n{\n  \"version\": 1,\n  \"locale\": \"en_US\",\n  \"platform\": \"3.4.4\",\n  \"metadata\": {\n    \"appmode\": \"api\",\n    \"primary_rmd\": null,\n    \"primary_html\": null,\n    \"content_category\": null,\n    \"has_parameters\": false\n  },\n  \"packages\": {\n    \"BH\": {\n      \"Source\": \"CRAN\",\n      \"Repository\": \"https://cran.rstudio.com/\",\n      \"description\": {\n        \"Package\": \"BH\",\n        \"Type\": \"Package\",\n        \"Title\": \"Boost C++ Header Files\",\n        \"Version\": \"1.66.0-1\",\n        \"Date\": \"2018-02-12\",\n        \"Author\": \"Dirk Eddelbuettel, John W. Emerson and Michael J. Kane\",\n        \"Maintainer\": \"Dirk Eddelbuettel <edd@debian.org>\",\nThe manifest file, application code, and supporting files are sent to the production RStudio Connect server.\nThe RStudio Connect server creates an isolated library for each piece of content.\nThe required packages are restored into the isolated library using the manifest file. As an example, if content A depends on ISLR 1.0 and content B depends on ISLR 2.0, the appropriate version will be installed into the separate content libraries. RStudio Connect maintains a cache so that packages are appropriately reused when possible.\nExample: renv and Docker\nIn this example, a Docker container is used to isolate the data product, and renv is used to snapshot and restore the appropriate package environment. More details are available for using R with Docker here.\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#vqojnwfypb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#vqojnwfypb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#vqojnwfypb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#vqojnwfypb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#vqojnwfypb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#vqojnwfypb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#vqojnwfypb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#vqojnwfypb .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vqojnwfypb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#vqojnwfypb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#vqojnwfypb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#vqojnwfypb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#vqojnwfypb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#vqojnwfypb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vqojnwfypb .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#vqojnwfypb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#vqojnwfypb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#vqojnwfypb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#vqojnwfypb .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#vqojnwfypb .gt_left {\n  text-align: left;\n}\n\n#vqojnwfypb .gt_center {\n  text-align: center;\n}\n\n#vqojnwfypb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#vqojnwfypb .gt_font_normal {\n  font-weight: normal;\n}\n\n#vqojnwfypb .gt_font_bold {\n  font-weight: bold;\n}\n\n#vqojnwfypb .gt_font_italic {\n  font-style: italic;\n}\n\n#vqojnwfypb .gt_super {\n  font-size: 65%;\n}\n\n#vqojnwfypb .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\n\n      Docker + renv Implementation\n    Snapshot\nrenv::snapshot() creates a lock file from the development environmentIsolate\nThe Docker container creates an isolated environment for the data productRestore\nrenv::restore() is run in the Docker container to recreate the package environment\n\nIn the development environment, create a renv.lock file for the project by running renv::snapshot(). The lock file records the version of the R packages in use. Commit this lock file alongside the code.\nCreate a Dockerfile, starting with the appropriate version of R:\n# start with the appropriate version of R\nFROM rstudio/r-base:3.4-bionic\n\n# install git\nRUN apt-get install -y git\n\n# clone the code base\nRUN git clone https://ourgit.example.com/user/project.git\n\n# install renv\nRUN R -e 'install.packages(\"renv\", repos = \"https://r-pkgs.example.com\")'\n\n# restore the package environment\nRUN R -e 'setwd(\"./project\"); renv::restore()'\n\n# run the data product\nCMD ...\nIn this example, the version of R is controlled by the base image, using an image provided by RStudio that includes R. Other alternatives also work, such as including the commands to install R. You can determine the R version from the renv lock file:\ncat renv.lock | grep -A1 \"\\[R\\]\" | sed -En \"s/Version=(.*)$/\\1/p\"\nBuild and deploy the docker image. This image contains the environment for your production code. The image can then be used as the basis for containers to execute your code.\nTesting and Staging Environments\nThe focus so far has been deploying R environments to production systems. With proper record keeping and environment isolation, there is a high chance that deployed content will work as expected. However, for systems that require minimal downtime, it is still imperative to test content in a pre-production system before officially deploying to production. The concept is simple:\nCreate and maintain a clone of the production system.\nFollow the steps described above to deploy the data product to the production clone.\nIf everything works as expected, re-run the steps to deploy the data product into production.\n\n\n{\"x\":{\"diagram\":\"\\ndigraph repos {\\n  graph [layout = dot\\n        rankdir = LR]\\n  \\n  \\n  node[shape = box]\\n  \\\"Dev\\\"\\n  \\n  node[fillcolor = grey, style = filled]\\n  \\\"Staging\\\"; \\\"Prod\\\"\\n  \\n  Dev -> Staging\\n  Staging -> Prod\\n}      \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\n\nStaging and Production should be identical clones!\nWhile conceptually simple, in practice there are two challenges:\nEnsuring the staging environment is a true clone of production.\nRepeating the same steps on both the clone and production system.\nTo solve these problems, most organizations use either containers or infrastructure-as-code. Luckily the idea is straight forward: instead of manually running this process, automate as much as possible by writing explicit code that accomplishes steps 1 and 2. The specific details for implementing these steps would require an entire website all their own, but most R users do not need to worry about re-inventing this process. Typically organizations will have a “DevOps” team or strategy in place for staging content. The main task for the R user is explaining how those tools should be adapted for data products using R. The adaptation is simply including our snapshot, isolate, and restore steps.\nExample: RStudio Connect with Git, Jenkins, and Chef\nIn this example, a DevOps team maintains staging and production servers using Chef. They also maintain an enterprise Git application and use Jenkins for continuous integration. The current DevOps strategy relies on Git branches. Branches of a repository are automatically deployed to staging, whereas the master branch is deployed to production. To integrate R based data products:\nThe DevOps team should create Chef recipes responsible for installing multiple versions of R onto the staging and production servers.\nThe DevOps team should create a Chef recipe to install and configure RStudio Connect.\nThe DevOps team should configure Jenkins to deploy a repository’s branches to the staging environment. Jenkins should also be configured to deploy the master branch to production. In both cases, the Jenkins pipeline will consist of bash shell scripts that clone the Git repository, create a tar file, and then call RStudio Connect API endpoints to deploy. Example shell scripts are available.\nWhen the R user is ready to deploy content, they should start by running rsconnect::writeManifest() inside of the development environment. The resulting manifest file should be included alongside the application code in a Git commit to a staging branch.\nFollowing the commit, Jenkins will deploy the code to the staging RStudio Connect environment, using the automatic process described above. The R user should confirm the content looks correct.\nThe user or admin can merge the staging branch into the master branch. This merge triggers a deployment to the production server.\n\n\n{\"x\":{\"diagram\":\"\\ndigraph repos {\\n  graph [layout = dot\\n        rankdir = LR]\\n  \\n  \\n  node[shape = box]\\n  \\\"Dev\\\"; \\\"Git Branch\\\"; \\\"Jenkins\\\"; \\\"Connect Staging\\\"; \\\"Git Master\\\"; \\\"Connect Prod\\\"; \\\"Jenkins \\\"\\n  \\n  node[fillcolor = grey, style = filled]\\n  \\\"Dependency Manifest\\\"; \\\"Code\\\"\\n  \\n  node[fillcolor = grey, style = filled, shape = oval]\\n  Approval\\n  \\n  Dev -> \\\"Dependency Manifest\\\"\\n  Dev -> \\\"Code\\\"\\n  \\\"Code\\\" -> \\\"Git Branch\\\"\\n  \\\"Dependency Manifest\\\" -> \\\"Git Branch\\\"\\n  \\\"Git Branch\\\" -> \\\"Jenkins\\\"\\n  \\\"Jenkins\\\" -> \\\"Connect Staging\\\"\\n  \\\"Connect Staging\\\" -> Approval\\n  Approval -> \\\"Git Master\\\"\\n  \\\"Git Master\\\" -> \\\"Jenkins \\\"\\n  \\\"Jenkins \\\" -> \\\"Connect Prod\\\" \\n}      \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nMore details are available here.\nAcceptable Differences\nWe’ve now described three environments: development, staging/testing, and production. The key to success is keeping these environments as similar as possible. However, what happens if your development environment is a Windows desktop, and production is a Linux server? This section outlines differences that are acceptable: the R patch version and the R source.\nR Patch Version\nR’s version scheme has there components, the major version, the minor version, and a patch. For example, R version 3.5.2 has:\n- Major version: 3\n- Minor version: 5\n- Patch version: 2\nMajor versions are released rarely. Minor versions are released once a year in the spring. Patch versions are released on a regular, as-needed basis. R packages are compatible across patch versions, but not major or minor versions!. As an example, a package built on version 3.5.1 will work on 3.5.2, but is not guaranteed to work on 3.6.0.\nFor the reason above, we recommend that development and production systems have the same available major.minor version, but the patch version could vary. For example, content created in the development environment using R version 3.5.1 could be deployed to a production environment using 3.5.2.\nR packages do not follow these same rules, and package versions should match exactly!\nR Package Source\nIt is possible for development and production environments to have different operating systems. For example, development could be performed on a Windows desktop, while production lives on a Linux server.\n\nWhile possible, this setup is not recommended. Instead, many organizations prefer to standardize on a single operating system, usually Linux. RStudio Server (Pro) makes it easy for R users to develop in an environment that more closely resembles production.\n\nIn the case where operating systems vary, the source of an R package may vary as well. Using the scenario above, R packages on Windows are typically installed from pre-compiled CRAN binaries. When the same packages are restored on a Linux system, they are normally installed from source. This difference will not impact behavior, but it explains why information about the package (name, version, repository) is transferred as opposed to transferring the installed package library.\nEnvironment Upgrades\nIn production, one does not simply upgrade packages or system dependencies! These tips can enable successful maintenance of your production system overtime:\nR Packages: You should not be worried about upgrading R packages. Recall, the whole goal of the Snapshot and Restore strategy is to recreate the necessary development dependencies in an isolated environment. To upgrade R packages, start by upgrading them in development, testing that the content works, and following the process to redeploy.\nR Versions: New R versions should be added instead of upgraded. Production systems must have multiple versions of R. As content is updated and redeployed, old versions of R will become less used and can eventually be removed. In order to accomplish this goal, R should be installed from source, not from a system repository using apt or yum. See R Installations for details.\nSystem Dependencies: System dependencies such as shared objects, compilers, or even the operating system are updated less frequently. Normally, these components are stable or strictly backwards compatible within an operating system release. These components should be updated in a staging environment. Often, major updates will require rebuilding R and redeploying content. For limited downtime, we recommend creating a clone of production, applying the update, and redeploying content. Once complete, swap the DNS records for this clone with the original production server. Production systems using Docker containers can mitigate this challenge, because Docker containers tend to isolate the entire system environment per data product.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:12+00:00"
    },
    {
      "path": "docker.html",
      "title": "Docker",
      "description": "Environment Management with Docker\n",
      "author": [],
      "contents": "\n\nContents\nDocker 101 for Data Scientists\nLayers in a Container\nBase Operating System\nSystem Dependencies\nR\nR Packages\nCode\nData\n\nExample Registries\nRocker Project\nR-Hub\nRStudio Images\n\n\nDocker is a large topic. This site focuses on how Docker relates to reproducible environments, specifically environments for R. R users and admins should be familiar with four key concepts: Dockerfiles, Images, Registries, and Containers. Then they should focus on the layers required in an image for R.\nDocker 101 for Data Scientists\nComputing in containers can be compared to brewing and drinking a beer. You start with a recipe that describes all the ingredients you’ll need. From the recipe, you make a batch of the beer. The batch is stored, ready for use. Finally, on specific occasions, you can pour a glass of beer and drink it.\nIn Docker, we have:\nDockerfile - Describes the steps needed to create an environment. This is the recipe.\nImage - When you execute the steps in a Dockerfile, you build the Dockerfile into an image which contains the environment you described. This is the batch of beer.\nRegistry - Stores built images, so that others can use them. This is akin to a liquor store.\nContainer - At a specific moment, you can start a container from the image, which amounts to running a process in the built environment. This is drinking a pint from the batch of beer.\n\n\nlibrary(DiagrammeR)\ngrViz(\"\n  digraph repos {\n  graph [layout = dot\n         rankdir = LR]\n  node[shape = box]\n  Dockerfile Image Container\n  \n  node[shape = box, style=filled, color=grey]\n  Registry \n  \n  Image -> Registry\n  Registry -> Image\n  \n  Dockerfile -> Image\n  Image -> Container\n}      \n\")\n\n\n\n{\"x\":{\"diagram\":\"\\n  digraph repos {\\n  graph [layout = dot\\n         rankdir = LR]\\n  node[shape = box]\\n  Dockerfile Image Container\\n  \\n  node[shape = box, style=filled, color=grey]\\n  Registry \\n  \\n  Image -> Registry\\n  Registry -> Image\\n  \\n  Dockerfile -> Image\\n  Image -> Container\\n}      \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nDocker is powerful because it allows you to create isolated, explicit environments where specific commands are run. In our analogy, the benefits are comparable to a group of friends going to a bar and ordering drinks:\nYou can easily pour many “replicas” of the same beer.\nThe bartender (a server, in computer terms), is decoupled from the beer we want - we don’t have to go to the brewer and brew a new beer each time we want a pint.\nAs a result, the same bartender can offer many different types of beers\nFor R users and admins, it is important to understand that containers are tied to a process. This is the key difference in most user’s experience between a container and a virtual machine. For R users, the process that is running can fall into two buckets:\n\n\nlibrary(gt)\nlibrary(dplyr)\nlibrary(tidyr)\nprocs <- data.frame(\n  dev = c(\"Create an analysis in a controlled environment\", \"RStudio\", \"IDE Session\", \"Changes are Saved\"),\n  prod = c(\"Run a production model\", \"R\", \"R -e shiny::runApp\", \"Read Only\"),\n  rowname_col = c(\"Use Case\", \"Runtime Entrypoint\", \"Example Process\", \"Code & Environment\")\n  , stringsAsFactors = FALSE\n)\n  \ngt(procs, rowname_col = \"rowname_col\") %>% \n  cols_label(dev = \"Development Session\", prod = \"Production Runtime\")\n\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ymecaojlif .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ymecaojlif .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ymecaojlif .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ymecaojlif .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ymecaojlif .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ymecaojlif .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ymecaojlif .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ymecaojlif .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ymecaojlif .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ymecaojlif .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ymecaojlif .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ymecaojlif .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ymecaojlif .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ymecaojlif .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ymecaojlif .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ymecaojlif .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ymecaojlif .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ymecaojlif .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ymecaojlif .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ymecaojlif .gt_left {\n  text-align: left;\n}\n\n#ymecaojlif .gt_center {\n  text-align: center;\n}\n\n#ymecaojlif .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ymecaojlif .gt_font_normal {\n  font-weight: normal;\n}\n\n#ymecaojlif .gt_font_bold {\n  font-weight: bold;\n}\n\n#ymecaojlif .gt_font_italic {\n  font-style: italic;\n}\n\n#ymecaojlif .gt_super {\n  font-size: 65%;\n}\n\n#ymecaojlif .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 65%;\n}\n\n      Development Session\n      Production Runtime\n    Use Case\nCreate an analysis in a controlled environment\nRun a production modelRuntime Entrypoint\nRStudio\nRExample Process\nIDE Session\nR -e shiny::runAppCode & Environment\nChanges are Saved\nRead Only\n\nLayers in a Container\nA data science container for R will contain six fundamental components:\nBase Operating System\nSystem Dependencies\nR\nR Packages\nCode\nData\nDocker images can inherit and build off of one another, allowing these six components to be layers together to form a complete image that inherits components from earlier base images.\n\n\ngrViz(\"\n digraph repos {\n  graph [layout = dot\n         rankdir = BT]\n  node[shape = box]\n  'Base OS (ubuntu xenial)'; 'System Dependency (libssl)'; 'R Version (3.5.2)'; 'R Packages (xgboost)'; 'Code (report.Rmd)'\n  \n  node[shape=oval color=grey style=filled]\n  'Command \\n (R -e rmarkdown::render)'\n  \n  'Base OS (ubuntu xenial)'->'System Dependency (libssl)'\n  'System Dependency (libssl)'->'R Version (3.5.2)'\n  'R Version (3.5.2)'->'R Packages (xgboost)'\n  'R Packages (xgboost)'->'Code (report.Rmd)'\n  'Code (report.Rmd)' -> 'Command \\n (R -e rmarkdown::render)'\n}         \n\")\n\n\n\n{\"x\":{\"diagram\":\"\\n digraph repos {\\n  graph [layout = dot\\n         rankdir = BT]\\n  node[shape = box]\\n  \\\"Base OS (ubuntu xenial)\\\"; \\\"System Dependency (libssl)\\\"; \\\"R Version (3.5.2)\\\"; \\\"R Packages (xgboost)\\\"; \\\"Code (report.Rmd)\\\"\\n  \\n  node[shape=oval color=grey style=filled]\\n  \\\"Command \\n (R -e rmarkdown::render)\\\"\\n  \\n  \\\"Base OS (ubuntu xenial)\\\"->\\\"System Dependency (libssl)\\\"\\n  \\\"System Dependency (libssl)\\\"->\\\"R Version (3.5.2)\\\"\\n  \\\"R Version (3.5.2)\\\"->\\\"R Packages (xgboost)\\\"\\n  \\\"R Packages (xgboost)\\\"->\\\"Code (report.Rmd)\\\"\\n  \\\"Code (report.Rmd)\\\" -> \\\"Command \\n (R -e rmarkdown::render)\\\"\\n}         \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nOne reason Docker is so successful is because the different layers in a container are cached. In the example above, you can layer with code, without rebuilding the entire image. Only the steps “above” the code layer are re-run to create the updated image. The order of layers is very important, because it impacts the caching involved and the build time of the image.\nIn addition to caching, Docker images can build off of one another. As an example, the first 3 layers could be pulled into their own image:\n\n\ngrViz(\"\n digraph repos {\n  graph [layout = dot\n         rankdir = BT]\n  node[shape = box]\n  'Base OS (ubuntu xenial)'; 'System Dependency (libssl)'; 'R Version (3.5.2)'; \n  \n  node[shape=box color=grey style=filled]\n  'Save as new base image \\n (company/base-r-image:3.5.2-xenial)'\n  \n  'Base OS (ubuntu xenial)'->'System Dependency (libssl)'\n  'System Dependency (libssl)'->'R Version (3.5.2)'\n  'R Version (3.5.2)'->'Save as new base image \\n (company/base-r-image:3.5.2-xenial)'\n}         \n\")\n\n\n\n{\"x\":{\"diagram\":\"\\n digraph repos {\\n  graph [layout = dot\\n         rankdir = BT]\\n  node[shape = box]\\n  \\\"Base OS (ubuntu xenial)\\\"; \\\"System Dependency (libssl)\\\"; \\\"R Version (3.5.2)\\\"; \\n  \\n  node[shape=box color=grey style=filled]\\n  \\\"Save as new base image \\n (company/base-r-image:3.5.2-xenial)\\\"\\n  \\n  \\\"Base OS (ubuntu xenial)\\\"->\\\"System Dependency (libssl)\\\"\\n  \\\"System Dependency (libssl)\\\"->\\\"R Version (3.5.2)\\\"\\n  \\\"R Version (3.5.2)\\\"->\\\"Save as new base image \\n (company/base-r-image:3.5.2-xenial)\\\"\\n}         \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\n\nBase images can be saved in a registry. The name and tags typically convey information about the image’s components and versions.\nOnce the base image is saved, additional images could extend the base image by adding the top layers:\nFROM company/base-r-image:3.5.2-xenial\nRUN ...\nThe following sections will cover each component, with a special emphasis on reproducible environments.\nBase Operating System\nMost Docker images start from a base operating system, the most common are versions of Ubuntu, CentOS, or Debian. These images are normally named by OS and tagged by release:\nFROM ubuntu:xenial\nFROM centos:centos6\nThis layer is the least likely to change, and is normally the “bottom” layer. For reproducibility, the Dockerfile should tag the desired release of the operating system.\nSystem Dependencies\nR itself requires a number of system libraries in order to run, and a further set of system libraries are needed if the image will build R from source. See this section for details.\nIn addition to the requirements for R, R packages often depend on system libraries. These dependencies can be determined manually by looking at the package’s Description file, or automatically using RStudio Package Manager or the sysreq R package.\nThe Dockerfile steps to install system libraries for R and system libraries for R packages are best separated. This separation allows you to change the two lists independently without re-installing everything.\nFROM ubuntu:xenial\n# Install system dependencies for R\nRUN apt-get update -qq && \\\n    DEBIAN_FRONTEND=noninteractive apt-get install -y \\\n    apt-transport-https \\\n    build-essential \\\n    curl \\\n    gfortran \\\n    libatlas-base-dev \\\n    libbz2-dev \\\n    libcairo2 \\\n    libcurl4-openssl-dev \\\n    libicu-dev \\\n    liblzma-dev \\\n    libpango-1.0-0 \\\n    libpangocairo-1.0-0 \\\n    libpcre3-dev \\\n    libtcl8.6 \\\n    libtiff5 \\\n    libtk8.6 \\\n    libx11-6 \\\n    libxt6 \\\n    locales \\\n    tzdata \\\n    zlib1g-dev\n    \n# Install system dependencies for the tidyverse R packages\nRUN apt-get install -y \\\n    make\n    libcurl4-openssl-dev\n    libssl-dev\n    pandoc\n    libxml2-dev\nNormally, system dependencies are reproducible within an operating system release. In the example above, the versions of each system dependency are not encoded in the Dockerfile explicitly because apt-get is implicitly providing versions that are known to be stable for the xenial Ubuntu release. This implicit versioning ensures the system dependencies are reproducible.\nR\nR can be added to a Docker image in one of three ways:\nStart from a base image that includes R.\nFROM rstudio/r-base:3.5-xenial\nInclude the commands to install R within an image.\n# download a version of R and build from source\nARG R_VERSION=3.5.2\nRUN wget https://cdn.rstudio.com/r/ubuntu-1604/pkgs/r-${R_VERSION}_1_amd64.deb\nRUN apt-get install -y gdebi-core\nRUN gdebi r-${R_VERSION}_1_amd64.deb\nInstall R using the system package manager, such as apt, yum, or zypper. See the details specific to your desired OS.\n# not the recommended approach\n# be sure you request a specific version of R\nRUN apt-get install -y \\\n  r-base=3.4.4-1ubuntu1\nThe key in any of the three methods is to be explicit about the version of R you want included in the image. Similar to R packages, being explicit prevents R from being updated as a side-effect of rebuilding the image, and instead ensures R upgrades are intentional.\nR Packages\nR packages are handled in a variety of ways. One approach is to include package installation in the Dockerfile which embeds the packages into the image. A second approach is to add appropriate R packages when the container is run.\nIn the former case, it is important to replace the standard install.packages command with a command that will return the same packages, regardless of when the Dockerfile is built into an image:\n#  install from a versioned repo\nRUN R -e 'install.packages(..., repo = \"https://rpkgs.company.com/frozen/repo/123\")'\n\nLearn more here\n# pull in a manifest file and restore it\nCOPY renv.lock ./\nRUN R -e 'renv::restore()'\n\nLearn more here\nUsing these types of commands ensures the package environment is maintained explicitly and upgraded intentionally, instead of having R packages upgraded as a side effect of an image rebuild (which can be hard to predict, due to the caching involved in image builds).\nA challenge to adding explicit package installation steps into Dockerfiles is the amount of time it takes to compile the Docker images increases dramatically. It can also be hard to add the packages’ build-time system requirements to the image. RStudio Package Manager helps resolve both challenges by providing pre-compiled R packages for different Linux operating systems. Using these binaries, the package installation step becomes a simple matter of moving a file into the container, and no compilation is necessary. Learn more here.\nThe second approach is to add packages into the container at runtime, instead of including them in the image. Packages added in this manner can be easier to cache, installed packages can effectively be mounted into the container. Similar to the first approach, tools like renv ensure the version stability. A downside to this approach is that reproducibility now relies on tracking the Docker run invocation in addition to the Dockerfile and image. The renv vignette on Docker provides more details.\n# example docker run command with renv\nRENV_PATHS_CACHE_HOST=/opt/local/renv/cache\nRENV_PATHS_CACHE_CONTAINER=/renv/cache\ndocker run --rm \\\n    -e \"RENV_PATHS_CACHE=${RENV_PATHS_CACHE_CONTAINER}\" \\\n    -v \"${RENV_PATHS_CACHE_HOST}:${RENV_PATHS_CACHE_CONTAINER}\" \\\n    R --vanilla --slave -e 'renv::activate(); renv::restore()'\nCode\nCode can be added to an image in three ways:\nCloning a Git repository\nRUN git clone https://git.company.com/jane/project.git\nMounting the files at run time using Docker volumes\nCopying the files into the image with COPY\nThe choice between these three options depends on the intended use of the container. If the container is being is used to execute production code, then option 1 is usually the most reliable choice, with option 3 serving as a fallback. If the container is being used for interactive development, mounting in files is the most common, because it ensures the changes to the code are persisted even after the docker container ends.\nA related question is whether or not RStudio should be included in the container. The answer depends on the use of the container: whether the container is being used to execute R code or being used to develop R code. In the first case, RStudio is not necessary. In the second case, RStudio should be involved. There are a variety of architectures for using RStudio with Docker, we recommend learning about the RStudio Launcher.\nData\nA data science container wouldn’t be much good without access to data! If the data is small, follow the suggestions above for code. If data is large, then don’t worry about moving the data into the container. Instead, focus on connecting the container to the data store. For example, the R code executed inside the container might connect to a database, in which case you’ll want to ensure the steps for installing the appropriate database drivers are added to the Dockerfile.\nExample Registries\nThis final section provides a quick list of references to projects using R and Docker. These projects can be useful as a way to source images for your own work, or serve as a catalog of Dockerfiles that can be tweaked, copied, or extended.\nKeep in mind, each project has a different goal and context. R users new to Docker should take care to understand why the project exists before using a project as the basis for new work.\nRocker Project\nThe Rocker project is a community driven effort to create a series of self-contained images for R development. These images can often be used as “virtual machines”. The image labels define their contents, e.g. the rocker/tidyverse image includes R and the tidyverse packages. The tag specifies the specific version of R used in the image. These images are all based off of the Debian OS.\nR-Hub\nR-Hub is a project designed to help R package authors prepare for CRAN package checks. As part of the project, R-Hub maintains a series of docker images designed to replicate the environments CRAN uses for testing. The image label includes key descriptions of the environment, for example, rhub/ubuntu-gcc-release includes the current R release version built with gcc on Ubuntu.\nRStudio Images\nRStudio provides a series of images designed to act as base layers for those using RStudio Launcher. These images contain minimal dependencies, but include standardized R installations compatible with package binaries. The label indicates the OS and R version, e.g rstudio/r-base:3.4-xenial is an image with R version 3.4 built on Ubuntu’s xenial release. For more information, visit the open source repository.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:14+00:00"
    },
    {
      "path": "index.html",
      "title": "Reproducible Environments",
      "description": "Manage environments for data science.\n",
      "author": [],
      "contents": "\nGreat data science work should be reproducible. Being able to repeat experiments is the foundation of all science. Reproducing work is also critical for business applications: scheduled reporting, team collaboration, project validation.\nThe purpose of this site is to help you understand the key use cases for reproducible environments, the strategies you can use to create them, and the tools you’ll need to master.\nWhile everyone should have a plan for reproducible environments, here are a few signs to suggest environment management has gone wrong:\nCode that used to run no longer runs, even though the code has not changed.\nYou are afraid to upgrade or install a new package, because it might break your code or someone else’s.\nTyping install.packages in your environment doesn’t do anything, or doesn’t do the right thing.\nIf you’re an individual data scientist, there are two things you should do before you continue any further with environment management: learn about RStudio Projects and use version control.\nIf you prefer videos to reading, checkout this webinar.\nUse Cases\nEnvironment management takes work. Here are some cases where the reward is worth the effort:\nWhen you are working on a long-term project, and need to safely upgrade packages.\nIn cases where you and your team need to collaborate on the same project, using a common source of truth.\nIf you need to validate and control the packages you’re using.\nWhen you are ready to deploy a data product to production, such as a Shiny app, R Markdown document, or plumber API.\nStrategies\nUse cases provide the “why” for reproducible environments, but not the “how”. There are a variety of strategies for creating reproducible environments. It is important to recognize that not everyone needs the same approach to reproducibility. If you’re a student reporting an error to your professor, capturing your sessionInfo() may be all you need. In contrast, a statistician working on a clinical trial will need a robust framework for recreating their environment. Reproducibility is not binary!\n\n\n\nFigure 1: Strategies for reproducibility fall on a spectrum. One side is not better than the other. Pick based on your goals.\n\n\n\nThere are three main strategies covered in this site.\nThe Snapshot and Restore strategy is used when individual data scientists are responsible for managing a project and have full access to install packages. The strategy uses tools like renv1 to record a project’s dependencies and restore them.\nThe Shared Baseline strategy helps administrators coordinate the work of many data scientists by providing common sets of packages to use across projects. The key to this strategy is determining a consistent set of packages that work together.\nThe Validated strategy is used when packages must be controlled and meet specific organization standards.\nThe strategy map will help you pick between the different strategies.\nTools\nData science environments are built from a common set of tools.\n\n\n\n{\"x\":{\"diagram\":\"digraph env {\\n\\n graph [layout = dot\\n        rankdir = BT]\\n node [shape = box]\\n \\\"Operating System\\\"\\n \\n node [shape = oval]\\n \\\"R Installation\\\"; \\\"System Libraries\\\"; \\\"Python Installation\\\"; \\\"virtualenv\\\"; \\\"Project Library\\\"\\n \\n node [shape = egg]\\n User\\n \\n \\\"Operating System\\\" -> \\\"Python Installation\\\"\\n \\\"Operating System\\\" -> \\\"System Libraries\\\"\\n \\\"Operating System\\\" -> \\\"R Installation\\\"\\n \\\"R Installation\\\" -> \\\"Project Library\\\"\\n \\\"System Libraries\\\" -> \\\"Project Library\\\"\\n \\\"System Libraries\\\" -> \\\"virtualenv\\\"\\n virtualenv -> User\\n \\\"Project Library\\\" -> User\\n \\\"Python Installation\\\" -> virtualenv\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 2: Components of an Environment\n\n\n\nIf you use a shared server, some elements might be shared amongst projects and some elements might exist more than once; e.g. your server might have multiple versions of R installed. If your organization uses Docker containers, you might have a base image with some of these components, and runtime installation of others. Understanding these tools will help you create reproducible environments.\nR Packages Managing and recording R packages makes up the bulk of this website. Specifically learn about repositories, installing packages, and managing libraries.\nR Installation Packages like renv will normally document the version of R used by the project. On shared servers, it is common to install multiple versions of R. Organizations using Docker will typically include R in a base image. Learn more best practices for R installations.\nOther Languages Often data science projects are multi-lingual. Combining R and Python is the most common use case, and tools like renv have affordances for recording Python dependencies.\nSystem Dependencies R, Python, and their packages can depend on underlying software that needs to be installed on the system. For example, the xml2 R package depends on the libxml system package. Learn more about how system dependencies are documented and managed.\nOperating System Operating system configurations can be documented with tools like Docker or through Infrastructure-as-code solutions like Chef and Puppet. Often this step is managed outside of the data science team. Learn more about best practices for Docker.\n\nrenv is packrat 2.0↩︎\n",
      "last_modified": "2021-10-28T18:55:15+00:00"
    },
    {
      "path": "installation.html",
      "title": "Installation",
      "description": "Installing Packages [In Progress]\n",
      "author": [],
      "contents": "\nThis page isn’t quite ready, but it will describe what a package is, what happens during installation, and the tools you can use to install packages.\nThe best resource for understanding package installation is Wickham’s “What is a package?”.\nMost R users are familiar with the R function install.packages. Here, we recommend two alternatives:\n1.The pak package is used to install packages interactively. pak is designed to help humans install packages quickly and safely.\nThe remotes package is used to install packages programmatically. remotes is designed with to help machines install package. The remotes package is intentionally lightweight and does not, itself, have any dependencies.1\n\nremotes powers devtools::install_ and is a suitable, lightweight alternative.↩︎\n",
      "last_modified": "2021-10-28T18:55:16+00:00"
    },
    {
      "path": "libraries.html",
      "title": "Libraries",
      "description": "Managing Installed Packages in Libraries\n",
      "author": [],
      "contents": "\n\nIn short, a library is just a directory containing installed packages\n\nHadley Wickham, R Packages\nYou can view your current libraries using:\n.libPaths()\nFor the purpose of reproducible environments, a library is the unit we ultimately want to reproduce. R libraries are subject to a few constraints that must be understood to reproduce them:\nOnly 1 version of each R package can be installed and accessed in a library at a time.\nR packages have complex dependency relationships, a working library must have a consistent set of packages that work together\nAn R library is tied to a specific version of R.\nR can search through multiple libraries, and libraries can be shared across projects and users.\nAddressing these constraints is the focus of the reproducible strategies.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:16+00:00"
    },
    {
      "path": "License.html",
      "author": [],
      "contents": "\ncreative commons\nAttribution-ShareAlike 4.0 International\nCreative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\nConsiderations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.\nConsiderations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor’s permission is not necessary for any reason–for example, because of any applicable exception or limitation to copyright–then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.\nCreative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 – Definitions.\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\nSection 2 – Scope.\nLicense grant.\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. __Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\nAttribution.\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\nSection 6 – Term and Termination.\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\nSection 7 – Other Terms and Conditions.\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\nSection 8 – Interpretation.\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org\n\n\n\n",
      "last_modified": "2021-10-28T18:55:17+00:00"
    },
    {
      "path": "python.html",
      "title": "Python",
      "description": "Environments with R and Python \n",
      "author": [],
      "contents": "\nPython is not the focus of this site, but it is a critical tool for many data scientists. Unfortunately managing Python environments can be challenging:\nFigure from https://xkcd.com/1987/At RStudio, we firmly believe in open source tools, and know that most data scientists and teams use both R and Python together. We continue to make this process easier. To learn more, visit: https://rstudio.com/python. Or if you like videos, this webinar demonstrates how to combine R and Python in a variety of ways.\nFor information on installing Python, especially on Linux servers, take advantage of these resources:\nSingle shared Python installation\nMultiple versions of Python, or multiple Jupyter Kernels\nFor current information on managing mixed R and Python projects, see the reticulate::use_* functions and the renv::use_python options.\nThese resources describe best practices for using Python in RStudio’s commercial products.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:18+00:00"
    },
    {
      "path": "R-installation.html",
      "title": "R Installations",
      "description": "Installing and Managing R \n",
      "author": [],
      "contents": "\nFor reproducible environments, the most critical step is installing R into a version specific directory. By doing so, your system can support multiple versions of R and avoid unintentional R upgrades.\nInstalling R\nRStudio provides pre-compiled packages that make it easy to install different versions of R side by side in Linux environments. To get started, visit these instructions or explore the open source repository.\nIn addition to the default R installation, there are a few options that customize R’s behavior:\nRenviron.site\nThis file lets you specify environment variables that should be available to any R session. The file is located at R_HOME/bin/R/etc, and has the format:\nVARIABLE=value\nThe system file is useful for specifying environment variables that should be available for all users accessing this version of R. For example, you might specify the PATH or set common ODBC settings.\nUser’s can create their own files, labelled .Renviron, that have the same format and place them in either their home directory (to apply to all projects) or their project directory (to apply to only a specific project). Often user’s will take advantage of these files to specify secrets such as passwords or API keys.\nRprofile.site\nSimilar to the environment file, the site-wide R profile allows you to supply R code that will be executed prior to the R session starting for any user accessing this version of R. The file is located at R_HOME/bin/R/etc, and has the format:\nlocal({\n  options(repos = c(CRAN = \"https://r-pkgs.example.com/cran\"))\n})\nUser’s can create their own default profile by creating a file called .Rprofile and saving it in their home directory (to apply to all projects) or their project directory (to apply to only a specific project).\nThe R profile is an easy way to set R specific options that can apply for all users.\nSystem Library\nEvery R installation includes a system library. Packages installed into the system library will be available to every user accessing that version of R. By default, the library is located at:\nR_HOME/lib/R/library\nNote that the library path should include a version number.\nThe easiest way to make a package available to all users is to install the package as a privileged user - R will automatically install the package into the system library in this case:\nsudo /opt/R/3.6.1/bin/R -e 'install.packages(\"ggplot2\")'\nWarning: This is an easy but dangerous option. If you want to make packages available to all users, we highly recommend the shared baseline strategy.\nIn addition to the system library, users will also have a default user library. This library is normally created in their home directory, and is also version specific.. When a user installs a package it is placed in this library and is not available to other users.\nTo see where R is looking for packages, run this command in R:\n.libPaths()\n# [1] \"/usr/home/sean/R/x86_64-pc-linux-gnu-library/3.6\"\n# [2] \"/opt/R/3.6.0/lib/R/library\"\nResources\nMore information is available on the R project homepage and this article on R’s start up behavior.\n\n\n\n",
      "last_modified": "2021-10-28T18:55:19+00:00"
    },
    {
      "path": "repositories.html",
      "title": "Repositories",
      "description": "R Package Repositories\n",
      "author": [],
      "contents": "\n\nContents\nStructure of a CRAN-like Repository\nPackage Metadata\nArchive Packages\nBinary Packages\n\nCharacteristics Specific to CRAN\nCRAN Mirrors\nCRAN checks\n\nOther CRAN-like Repositories\nBioConductor\nR-Forge\nrOpenSci\n\nInternal Repositories\n\n\n\n\nEvery new R user quickly discovers that packages are how work gets done in R. To understand how to manage R packages, it is important to start by understanding where R packages come from. The majority of R users install packages from the Comprehenisve R Archive Network (CRAN). CRAN is a network of servers that distribute R along with R packages.\nCRAN is not the only place where users can access packages. In addition to CRAN, there are a number of other CRAN-like repositories, such as R-Forge and BioConductor. These CRAN-like repositories have a similar structure to CRAN, and normally work with install.packages. Finally, some users access packages from locations such as GitHub. Unlike CRAN-like repositories, these locations require a different installation client.\nTo see your current repository setting, run:\ngetOption(\"repos\")\nIn RStudio 1.2 and above, users can change their repository by going to Tools -> Global Options -> Packages. RStudio Server administrators have a number of options for setting a repository for users.\nThis page outlines the structure of a CRAN-like repository, covers specific details about CRAN, and discusses options for creating internal repositories.\nLooking for a way to manage your own repository? Try RStudio Package Manager.\nStructure of a CRAN-like Repository\nCRAN-like repositories organize R packages in a specific structure designed to work with R’s functions for accessing and installing packages.\nThis structure can be seen in the file system of a CRAN-like repository, parts of which are highlighted below.\n/\n/src/contrib\n  package_1.0.tar.gz\n  PACKAGES.rds\n  PACKAGES.gz\n  PACKAGES\n    /PATH\n      package_1.2.tar.gz\n    /Archive/\n      /package/\n        package_0.9.tar.gz\n/bin\n  /windows/contrib\n    /3.3\n    /3.4\n      /PACKAGES\n      /package_1.0.zip\n  /macosx/\n    /contrib\n      /3.3\n      /3.4\n        /PACKAGES\n        /package_1.0.tgz\n    /mavericks\n    /leopard\n    /el-capitan\nThe structure of the repository is built around the different ways users might access packages. The /src/contrib directory contains the package source bundles. The /bin directory contains compiled packages, built for different distributions. More information about binary packages is available below.\nPackage Metadata\nAt the heart of a CRAN-like repository is a metadata file named PACKAGES. The metadata file enumerates what packages are available in the repository, as well as information about each package such as the packages name, version, and dependencies. The metadata file is available in three formats, not all three are required.\nArchive Packages\nCRAN, and some CRAN-like repositories, have an Archive directory inside of /src/contrib. This directory contains older versions of source packages, or packages that have been archived. On CRAN, there is additional metadata in an archive.rds file with information on the prior versions. These copies of prior package versions are critical to many reproducibility strategies.\nBinary Packages\nThe /bin directory contains binary versions of R packages along with appropriate metadata. The binaries are organized by distribution. A binary package is an R package that has been installed onto a specific operating system. The installation process can include compiling code as well as package documentation and metadata. Binaries can be reused on similar operating systems, and are important because they allow users who want access to a package to install it much faster. For example, if you use R on a Windows desktop, and want access to ggplot2, you have two options. You could use install.packages('ggplot2', type = 'source'), in which case R would request the latest ggplot2 source bundle, e.g. /src/contrib/ggplot2_1.0.tar.gz. After downloading the bundle, R would unpack the source code and compile it. This process can take significant time. In contrast, the second and default option, install.packages('ggplot2'), instructs R to first try and download a binary, e.g. /bin/windows/contrib/ggplot2_1.0.zip. If the binary is available, R can download and use the code as-is, with no installation necessary. You can think of CRAN binaries as being a global cache, the work of compiling is done once (per operating system), and all users benefit!\nMore detailed information on package installation is available as well as information on the different states of an R package.\nCRAN provides binaries for Windows and Mac. In addition to being distribution-specific, binaries are also specific to the version of R that created them. A repository serving binary packages indexes them by both attributes. Typically if a binary is not available for the version of R in-use, R will provide the user with an option to install the latest version from source, or install an older, binary version of the package that was built with the appropriate version of R. Additional details are available in the package installation section.\nRStudio Package Manager supplements the binaries available from CRAN and provides binary packages for a variety of Linux distributions. More information is available here](https://blog.rstudio.com/2019/11/07/package-manager-v1-1-no-interruptions/). These pre-compiled packages can make package installation much faster for those using R on Linux, such as RStudio Server users or anyone running R in Docker.\nCharacteristics Specific to CRAN\nCRAN-like repositories share many of the structural attributes described above, but there are specific features of CRAN that make it unique and remarkably successful. Two notable features include a distribution network of CRAN mirrors and testing of submitted packages. CRAN documents these policies and all of its policies here.\nCRAN Mirrors\nCRAN distributes R and and R packages through a network of “mirror” servers. Currently, the majority of R users install packages from two unique mirrors: httpd://cloud.r-project.org and httpd://cran.rstudio.com. These two mirrors are actually CDNs that use many servers world-wide to distribute packages. The RStudio CRAN mirror includes download logs that can be used to analyze package data.\nCRAN checks\nA unique feature of CRAN is the package submission process. Unlike many language repositories, CRAN requires R packages to pass a series of tests before the packages are accepted into the repository. These checks test to ensure the package is correctly formatted, and notably, also check to ensure the package does not break any other current packages on CRAN. You can read details and advice on the CRAN checks as well as related advice on how to pick a package and how to think about using packages in validated environments.\nOther CRAN-like Repositories\nIn addition to CRAN, there are a handful of other popular package repositories. The following list is not comprehensive.\nBioConductor\nBioConductor is a set of repositories containing R packages used in the analysis of genomic data. Three critical ways BioConductor differs from CRAN:\nBioConductor includes a number of data packages that are significantly larger than the max size limit for CRAN packages.\nBioConductor packages are all versioned and released together, as opposed to CRAN packages which are released individually on a rolling basis. This release mechanism is necessary because the packages are closely coupled.\nWhile BioConductor follows a CRAN-like structure, users are encourage to interact with the repository through a custom installation client instead of using install.packages directly.\nBioConductor packages are often used alongside of CRAN packages.\nR-Forge\nR-Forge is a collection of R projects and packages. Many R-forge packages are available in the R-Forge repository and CRAN. R-Forge projects additionally have mailing lists, message boards, forums, and other options that provide details about the related packages.\nrOpenSci\nrOpenSci is a collection of packages that adhere to a stricter set of development standards, curated by a community of package maintainers and reviewers. The majority of rOpenSci packages are also available on CRAN, though they can be downloaded directly from a CRAN-like repository built directly on-top of the packages’ Git repositories using drat.\nInternal Repositories\nMany organizations find value in hosting their own package repository. Hosting an internal repository allows organizations to:\nshare and version their internal packages\naccess and govern packages from external sources\naudit package use\nInternal repositories also play a critical role in many reproducibility strategies and can help teams collaborate on code. There are many ways organizations can create internal repositories. An open source option is the miniCRAN package. A professional, supported option is RStudio Package Manager. In addition to hosting an internal repository, RStudio Package Manager includes support for:\nrepository versioning\nusage tracking\nbrowsing packages\nautomatically building internal packages from Git\nserving subsets of CRAN\npre-compiled packages for Linux\n\n\n\n",
      "last_modified": "2021-10-28T18:55:19+00:00"
    },
    {
      "path": "reproduce.html",
      "title": "Strategy Maps",
      "description": "Strategies to Reproduce Environments Over Time\n",
      "author": [],
      "contents": "\n\nContents\nWild West\nTicket System\nBlocked\n\nReproducing data science work is the main objective of environment management. This site details three strategies for reproducing R environments over time. To select a strategy, you will need to answer two questions:\nWho is responsible for managing the environment?\nHow open is the environment?\nAt first these two questions might seem similar, but separating the two uncovers common “danger zones” or “anti-strategies”. The map below depicts these danger zones as well as three successful strategies. Use the map and the two questions above to determine where your organization currently operates and identify which strategy to move towards.\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(ggrepel)\nlibrary(plotly)\nmm <- tribble(\n  ~x, ~y, ~label, ~Description, ~status,\n  0.1, 0.1, 'Validated', 'Admins test and approve \\n a subset of CRAN', TRUE,\n  0.5, 0.5, 'Shared Baseline', 'All or most of CRAN, \\n updated with R versions, \\n tied to a system library', TRUE,\n  0.5, 0.75, 'Wild West', 'Open access, \\n not reproducible, \\n how we learn', FALSE,\n  0.8,0.8, 'Snapshot', 'Open access, user or system \\n records per-project dependencies', TRUE,\n  0.75, 0.2, 'Blocked', 'Backdoor package access, \\n offline systems without a strategy', FALSE,\n  0.2, 0.8, 'Ticket System', 'Admins involved, \\n no testing, \\n slow updates, \\n high risk of breakage', FALSE\n)\nbad1 <- tribble(\n  ~x, ~y, ~label, ~Description, ~status,\n  0, 0.2, NA, NA, NA,\n  0, 1,NA, NA, NA,\n  0.8, 1, NA, NA, NA\n)\n\nbad2 <- tribble(\n  ~x, ~y, ~label, ~Description, ~status,\n  0.2, 0, NA, NA, NA,\n  1, 0,NA, NA, NA,\n  1, 0.8, NA, NA, NA\n)\n\ngood <- tribble(\n  ~x, ~y, ~label, ~Description, ~status,\n  0, -0.2,NA, NA, NA,\n  1, 0.8, NA, NA, NA,\n  0.8, 1, NA, NA, NA,\n  0, 0.2, NA, NA, NA\n)\n\ngood2 <- tribble(\n  ~x, ~y, ~label, ~Description, ~status,\n  0, 0,NA, NA, NA,\n  0, 0.2, NA, NA, NA,\n  1, 0.8, NA, NA, NA,\n  0.2, 0, NA, NA, NA\n)\n\np <- ggplot(mm, aes(x, y)) + \n  geom_abline(slope = 1, intercept = 0.2, alpha = 0.2) + \n  geom_polygon(aes(x,y, text = Description), fill = \"red\", data=bad1, alpha = 0.1) + \n  geom_polygon(aes(x,y, text = Description), fill = \"green\", data=good, alpha = 0.1) + \n  geom_polygon(aes(x,y, text = NULL), fill = \"green\", data=good2, alpha = 0.1) + \n  geom_polygon(aes(x,y, text = Description), fill = \"red\", data=bad2, alpha = 0.1) +\n  geom_abline(slope = 1, intercept = -0.2, alpha = 0.2) + \n  geom_point(aes(x, y, color = status, text = Description)) + \n  geom_text(aes(x, y, label = label), nudge_y = 0.025, nudge_x  = 0.025) + \n  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,0.25), labels = c(\"Admins\",\"\", \"\", \"\", \"Users\")) +\n  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.25), labels =  c(\"Locked Down\",\"\", \"\", \"\", \"Open\")) +\n  theme_minimal() + \n  scale_color_manual(breaks = NULL, values = c(\"#ff0000\",\"#a3c586\")) + \n  \n  labs(\n    x = \"Who is Responsible for Reproducing the Environment?\",\n    y = \"Package Access\",\n    color = NULL,\n    title = \"Reproducing Environments: Strategies and Danger Zones\"\n  ) # + \n  # theme(axis.line = element_line(linetype = 'solid', arrow = grid::arrow(length = grid::unit(1, units = 'mm'))))\nggplotly(p, tooltip = c('text')) %>% \n  config(displayModeBar = FALSE) %>% \n  style(hoverinfo = 'skip', traces = 1:5) %>% \n  hide_legend()\n\n\n\n{\"x\":{\"data\":[{\"x\":[-0.05,1.05],\"y\":[0.15,1.25],\"text\":\"\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,0.2)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"skip\",\"frame\":null},{\"x\":[0,0,0.8,0],\"y\":[0.2,1,1,0.2],\"text\":\"NA\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\",\"dash\":\"solid\"},\"fill\":\"toself\",\"fillcolor\":\"rgba(255,0,0,0.1)\",\"hoveron\":\"fills\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"skip\",\"frame\":null},{\"x\":[0,1,0.8,0,0],\"y\":[null,0.8,1,0.2,null],\"text\":\"NA\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\",\"dash\":\"solid\"},\"fill\":\"toself\",\"fillcolor\":\"rgba(0,255,0,0.1)\",\"hoveron\":\"fills\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"skip\",\"frame\":null},{\"x\":[0,0,1,0.2,0],\"y\":[0,0.2,0.8,0,0],\"text\":\"\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\",\"dash\":\"solid\"},\"fill\":\"toself\",\"fillcolor\":\"rgba(0,255,0,0.1)\",\"hoveron\":\"fills\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"skip\",\"frame\":null},{\"x\":[0.2,1,1,0.2],\"y\":[0,0,0.8,0],\"text\":\"NA\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\",\"dash\":\"solid\"},\"fill\":\"toself\",\"fillcolor\":\"rgba(255,0,0,0.1)\",\"hoveron\":\"fills\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"skip\",\"frame\":null},{\"x\":[-0.05,1.05],\"y\":[-0.25,0.85],\"text\":\"\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,0.2)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[0.5,0.75,0.2],\"y\":[0.75,0.2,0.8],\"text\":[\"Open access, <br /> not reproducible, <br /> how we learn\",\"Backdoor package access, <br /> offline systems without a strategy\",\"Admins involved, <br /> no testing, <br /> slow updates, <br /> high risk of breakage\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(255,0,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(255,0,0,1)\"}},\"hoveron\":\"points\",\"name\":\"FALSE\",\"legendgroup\":\"FALSE\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[0.1,0.5,0.8],\"y\":[0.1,0.5,0.8],\"text\":[\"Admins test and approve <br /> a subset of CRAN\",\"All or most of CRAN, <br /> updated with R versions, <br /> tied to a system library\",\"Open access, user or system <br /> records per-project dependencies\"],\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(163,197,134,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(163,197,134,1)\"}},\"hoveron\":\"points\",\"name\":\"TRUE\",\"legendgroup\":\"TRUE\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[0.125,0.525,0.525,0.825,0.775,0.225],\"y\":[0.125,0.525,0.775,0.825,0.225,0.825],\"text\":[\"Validated\",\"Shared Baseline\",\"Wild West\",\"Snapshot\",\"Blocked\",\"Ticket System\"],\"hovertext\":[\"\",\"\",\"\",\"\",\"\",\"\"],\"textfont\":{\"size\":14.6645669291339,\"color\":\"rgba(0,0,0,1)\"},\"type\":\"scatter\",\"mode\":\"text\",\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":89.8630136986302},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Reproducing Environments: Strategies and Danger Zones\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.05,1.05],\"tickmode\":\"array\",\"ticktext\":[\"Admins\",\"\",\"\",\"\",\"Users\"],\"tickvals\":[0,0.25,0.5,0.75,1],\"categoryorder\":\"array\",\"categoryarray\":[\"Admins\",\"\",\"\",\"\",\"Users\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Who is Responsible for Reproducing the Environment?\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.05,1.05],\"tickmode\":\"array\",\"ticktext\":[\"Locked Down\",\"\",\"\",\"\",\"Open\"],\"tickvals\":[0,0.25,0.5,0.75,1],\"categoryorder\":\"array\",\"categoryarray\":[\"Locked Down\",\"\",\"\",\"\",\"Open\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Package Access\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false,\"displayModeBar\":false},\"source\":\"A\",\"attrs\":{\"747f179cf013\":{\"intercept\":{},\"slope\":{},\"type\":\"scatter\"},\"747f36bf43f\":{\"x\":{},\"y\":{},\"text\":{}},\"747f637f142d\":{\"x\":{},\"y\":{},\"text\":{}},\"747f564ded89\":{\"x\":{},\"y\":{}},\"747f5075b863\":{\"x\":{},\"y\":{},\"text\":{}},\"747f5c7f1bc3\":{\"intercept\":{},\"slope\":{}},\"747f26f6b767\":{\"x\":{},\"y\":{},\"colour\":{},\"text\":{}},\"747fde1fdfc\":{\"x\":{},\"y\":{},\"label\":{}}},\"cur_data\":\"747f179cf013\",\"visdat\":{\"747f179cf013\":[\"function (y) \",\"x\"],\"747f36bf43f\":[\"function (y) \",\"x\"],\"747f637f142d\":[\"function (y) \",\"x\"],\"747f564ded89\":[\"function (y) \",\"x\"],\"747f5075b863\":[\"function (y) \",\"x\"],\"747f5c7f1bc3\":[\"function (y) \",\"x\"],\"747f26f6b767\":[\"function (y) \",\"x\"],\"747fde1fdfc\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\",\".hideLegend\":true},\"evals\":[],\"jsHooks\":[]}\nThe three strategies are outlined in detail:\nSnapshot and Restore\nShared Baseline\nValidated\nIn addition to these three strategies, the strategy map above details a set of danger zones, areas where “who” is in control and “what” can be installed are mis-aligned to create painful environments that can not be reliably recreated. Identifying if you’re in a danger zone can help you identify a “nearby” strategy to move towards.\nWild West\nThe wild west scenario occurs when users are given free reign to install packages with no strategy for reproducing package environments.\nRecommendations:\nIf you are a single data scientist, or in a team of experienced data scientists, consider moving to the snapshot and restore strategy.\nIf you are working with a group of newer users, consider working with IT to setup the shared baseline strategy. Be careful not to slip into the ticket system scenario, which occurs if you ask IT to restrict the system without teaching them how to manage shared baselines. It might make sense to use the shared baseline strategy by default, and allow experienced users to step into the snapshot strategy.\nTicket System\nThe ticket system scenario occurs when administrators are involved in package installation, but they do not have a strategy for ensuring consistent and safe package updates; for example:\nA user wants a new package installed, so they submit a ticket to have the package added\nAn admin receives the ticket, and manually installs the new package into the system library\nThis scenario is problematic because it encourages partial upgrades, is often slow, and still results in broken environments!\nRecommendation\nIf your organization requires admin involvement for practical reasons, (e.g. you’re working on offline server), consider adopting the shared baseline strategy.\nIf your organization requires admin involvement for strategic reasons (e.g. you have concerns about package licenses), consider adopting the validation strategy.\nBlocked\nThe blocked scenario occurs when servers are locked down, but there is no strategy in place for R package access. This strategy often leads R users to “backdoor” approaches to package access, such as manually copying over installed packages.\nIn this scenario, it is important for R users to level-set with IT on why R packages are essential to successful data science work. You may need to refer to the validation section of the site or the section on picking packages, both of which help explain where packages come from and address issues around trust.\nCome to this discussion prepared to advocate for either the shared baseline or validation strategy. It may also help your admin team to know that there are supported products, like RStudio Package Manager, designed to help them help you!\n\n\n\n",
      "last_modified": "2021-10-28T18:55:22+00:00"
    },
    {
      "path": "shared.html",
      "title": "Shared Baselines",
      "description": "Share a Common Baseline\n",
      "author": [],
      "contents": "\n\nContents\nThe BIG Risk\nImplementation Steps\nCommon Challenges and Resolutions\n\nThe shared baseline strategy fits when administrators or R champions are responsible for creating an environment where less experienced users can easily share and re-run work. The defining characteristics of the strategy are:\nThere are not strict requirements on what can be installed, the main motivation is ease of sharing.\nPackage availability is tied to R installations through site-wide libraries, and updates occur on a scheduled basis.\nA naive approach to this strategy is for an admin to install packages into a system library as users request them. Unfortunately, this approach is not a strategy but actually the Ticket System danger zone! Before diving into the implementation steps, we need to understand the problem with this approach.\nThe BIG Risk\nImagine the following scenario:1\nJanuary 1st, an admin installs tibble into the system library. The package is installed, along with the package’s dependencies. Everything is in a consistent state because the packages all originate from CRAN on the same date, and CRAN tests to ensure the “latest” packages all work together.\n\n\nlibrary(DiagrammeR)\ngrViz(\"\ndigraph first {\n  node [shape = oval]\n  rlang; cli; crayon;\n  \n  node [shape = box]\n  tibble\n  \n  tibble->rlang\n  tibble->cli\n  tibble->crayon\n}\n\")\n\n\n\n\n{\"x\":{\"diagram\":\"\\ndigraph first {\\n  node [shape = oval]\\n  rlang; cli; crayon;\\n  \\n  node [shape = box]\\n  tibble\\n  \\n  tibble->rlang\\n  tibble->cli\\n  tibble->crayon\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Partial Dependency Graph for tibble\n\n\n\nFebruary 1st, the admin receives a request to install pkgdown. In doing so, pkgdown is installed along with its dependencies, which include rlang, cli, and crayon. Already there is a problem, any users who relied on the older versions of cli, crayon, and rlang could see their code break with no warning. But, the problem gets worse! Even though its dependencies were updated, tibble was not. The result is an inconsistent state, where some packages come from February 1st and some from January 1st. This mixed set is not tested by CRAN, and can lead to an error for anyone using tibble.\n\n\ngrViz(\"\ndigraph first {\n  node [shape = oval\n        style = filled\n        fillcolor = grey]\n  rlang; cli; crayon\n  \n  node [shape = box\n        style = filled\n        fillcolor = grey]\n  pkgdown\n  \n  node [shape = box\n        style = filled\n        fillcolor = white]\n  tibble\n  \n  tibble->rlang\n  tibble->cli\n  tibble->crayon\n  pkgdown->rlang\n  pkgdown->cli\n  pkgdown->crayon\n}\n\")\n\n\n\n\n{\"x\":{\"diagram\":\"\\ndigraph first {\\n  node [shape = oval\\n        style = filled\\n        fillcolor = grey]\\n  rlang; cli; crayon\\n  \\n  node [shape = box\\n        style = filled\\n        fillcolor = grey]\\n  pkgdown\\n  \\n  node [shape = box\\n        style = filled\\n        fillcolor = white]\\n  tibble\\n  \\n  tibble->rlang\\n  tibble->cli\\n  tibble->crayon\\n  pkgdown->rlang\\n  pkgdown->cli\\n  pkgdown->crayon\\n}\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 2: A dangerous situation, resulting from a partial upgrade\n\n\n\n\nWhite - January Versions Grey - February Versions\nThe benefit of the shared baseline approach is that everyone uses the same installed packages. The problem is if an administrator updates packages, the update could create an inconsistent state that breaks other users’ code. The main benefit has turned into a big risk!\n\nNote: This scenario can also occur for individual users who share a package library across projects. The likelihood of conflict just increases if multiple users share a library.\n\nHow do we prevent this problem? One option would be for an administrator to install all the packages at once. Unfortunately, this option rarely works in practice because it is incredibly time intensive and users don’t know upfront the entire list of packages they’ll need.\nFrozen Repositories\nA better option is to rely on a frozen repository. A frozen repository is a way for organizations to always get a consistent set of packages, without having to pre-install all the packages. As an example, you could rsync CRAN to an internal server on January 1st and host it at https://r-pkgs.example.com/cran/012019. Then, no matter when an admin installs new packages, they will always get a consistent set of packages. The next time a version of R is released, the new version of R can be associated with a new frozen repository, e.g. https://r-pkgs.example.com/cran/062019, allowing users to access updated and new packages while still remaining consistent. The specific steps for this approach are documented below.\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(lubridate)\nlabels <- tribble(\n  ~x, ~y, ~label, ~color,\n  \"04-01-2018\", 0.75, \"R 3.4.4 \\n Repo Frozen \\n 042018\", \"grey\",\n  \"07-01-2018\", 1.75, \"R 3.5.1 \\n Repo Frozen \\n 072018\", \"darkblue\",\n  \"10-15-2018\", 1.65, \"Projects gradually \\n  migrate\", \"darkred\"\n)\ntext <- tribble(\n  ~x, ~y, ~label, ~color,\n  \"05-01-2018\", 1.15, \"pkgdown 1.0 installed \\n rlang 0.2.0 installed\", \"grey\",\n  \"09-01-2018\", 1.15, \"tibble 1.4.2 installed \\n rlang 0.2.0 still used\", \"grey\",\n  \"08-01-2018\", 2.15, \"pkgdown 1.1.0 installed \\n rlang 0.2.1 installed\", \"darkblue\"\n)\ntimeline1 <- tribble(\n  ~x, ~y,\n  '04-01-2018', 1,\n  '10-01-2018', 1,\n)\ntimeline2 <- tribble(\n  ~x, ~y,\n  '07-01-2018', 2,\n  '12-01-2018', 2,\n)\n\ntimeline1$x <- mdy(timeline1$x)\ntimeline2$x <- mdy(timeline2$x)\nlabels$x <- mdy(labels$x)\ntext$x <- mdy(text$x)\n\nggplot() + \n  theme_minimal() + \n  geom_label(data = labels, aes(x, y, label = label, color = color)) + \n  geom_text(data = text, aes(x, y, label = label, color = color)) + \n  geom_path(data = timeline1, aes(x,y), color = \"black\") + \n  geom_path(data = timeline2, aes(x,y), color = \"darkblue\")  + \n  scale_y_continuous(breaks = NULL, limits = c(0.5,2.5)) +\n  scale_x_date(limits = c(as.Date(mdy(\"03-01-2018\")),as.Date(mdy(\"12-01-2018\")))) + \n  scale_color_manual(values = c(\"darkblue\", \"darkred\", \"black\"), guide = FALSE) +\n  labs(\n    color = NULL,\n    y = NULL,\n    x = \"Calendar Time\"\n    \n  )\n\n\n\n\nFigure 3: Shared Basline Strategy\n\n\n\nOvertime, managing these repositories can become tedious, RStudio Package Manager provides an easy way to automatically access snapshots and additionally optimizes disk space and supports internal, non-CRAN packages.\nImplementation Steps\nThis strategy requires a “frozen repository”, as described above. Organizations can create frozen repositories manually, tie into MRAN, or use RStudio Package Manager.\nInstall a version of R. This results in a versioned system library:\n/opt/R/3.4.4/lib/R/library\nCreate or edit the Rprofile.site file, to set the repo option for this version of R to point to a frozen repository.\n\n# /opt/R/3.4.4/etc/Rprofile.site\nlocal({\n  options(repos = c(CRAN = \"https://r-pkgs.example.com/cran/128\"))\n})\n\nRun R as root, and install the desired baseline packages. Overtime, as requests for new packages come in, install them in the same way. Consistency is guaranteed because you are always installing from the same frozen repository.\nsudo /opt/R/3.4.4./bin/R -e 'install.packages(\"ggplot2\")'\nUsers access packages on the server without any need to install, e.g.: library(ggplot2)\n(Optionally) Disable the user option to change the repository setting and discourage package installation.\n\n# /etc/rstudio/rsession.conf\nallow-r-cran-repos-edit=0\nallow-package-installation=0\n\n(Optionally) Allow users to install packages into their personal user libraries. The user library is still tied to the R version, and the repository is still frozen due to the Rprofile.site setting. In this case, users won’t all have the same packages, but if they share code and then install packages, they’ll get the same versions.\nCommon Challenges and Resolutions\nDesktop R Users\nThe implementation described for the shared baseline strategy assumes users are accessing R on a shared server, using a tool like RStudio Server (Pro). Often, teams of data scientists using R from their desktops also want easy collaboration and the benefits of uniform package versions. This result is possible by adapting the strategy. Desktop users simply need to set their repository option to use a frozen repository. If all users pick the same frozen repository, they’ll get the benefits of the strategy. Desktop users can set the repository using the Rprofile.site mechanism, or using a wizard available in RStudio (v1.2+) Tools -> Global Options -> Packages.\nNew or Updated Packages\nWhat happens if a package is updated immediately after the shared baseline is implemented? Or a new package is added? For example, what would happen if the repository is frozen on April 1st, and April 5th a new package is added? In this case, users would need to wait until the next release to pull in this update. We recommend organizations roll out new versions of R (and new package sets) every 4-6 months.\nLuckily, this type of time delay will not impact most R users. The need to access the latest and greatest packages is rare for the majority of R users, especially new R users. We recommend allowing advanced R users who require this type of “bleeding edge” access to use the Snapshot and Restore strategy. If a critical security issue arises that requires a package update, re-install the version of R in a new directory, e.g. /opt/R/3.4.4-patch/ and follow the entire process, perhaps removing the old R version.\nInternal Packages\nThe shared baseline strategy works with internal packages as long as those packages are available in a frozen, CRAN-like repository. RStudio Package Manager makes it easy to include internal packages in repository checkpoints.\nDocker\nDocker can be used alongside the shared baseline strategy to ensure that rebuilding a Docker image always returns the same sets of packages. Docker makes the process easier, because it negates the need to manage a system library shared by multiple users.\n\nFROM ubuntu\n...\n# To install packages\nRUN R -e 'install.packages(..., repo = \"https://r-pkgs.example.com/cran/042018\")'\n# Or set the repo option if users will install packages in the container\nRUN echo 'options(repos = c(CRAN = \"https://r-pkgs.example.com/cran/042018\"))' > .Rprofile\n\n\nThe scenario is hypothetical and simplified, you should not be concerned about the specific packages and dates used in the example.↩︎\n",
      "last_modified": "2021-10-28T18:55:25+00:00"
    },
    {
      "path": "snapshot.html",
      "title": "Snapshot and Restore",
      "description": "Snapshot Project Dependencies and Restore Them\n",
      "author": [],
      "contents": "\n\nContents\nPre-requisite Steps:\nStep 1: Initalize a Project\nStep 2: Install and Use Packages\nStep 3: Snapshot the Environment\nStep 4: Recreate the Environment\nWatch a video demo of Snapshot and Restore with renv\nImplementing the Snapshot Strategy in Production\nCommon Challenges and Resolutions:\nAdditional Resources:\n\nThe snapshot and restore strategy fits when package access is open and users are responsible for reproducibility. This strategy is the most relevant for individual data scientists. The strategy has two key characteristics:\nUsers are able to freely access and install packages for a project\nUsers have the full responsibility to record the dependencies needed for a project\nThe strategy is implemented with the following steps:\nStart a project by creating a project-specific library\nInstall and use packages from the project-specific library\nRecord the state of the library alongside of the code\nRestore the library when the environment needs to be recreated\nA potential drawback of this strategy is the involvement required from the R user. For new users, these steps can create an energy barrier that prevents them from being successful. Often organizations will start new users (e.g. Excel converts) with a different strategy, and allow power R users the flexibility and responsibility of this strategy.\n\n\n\n{\"x\":{\"diagram\":\"\\ndigraph renv {\\n  graph [layout = dot\\n         rankdir = LR]\\n  node [shape = box]\\n  \\\"1. Create a Project\\\"; \\\"Write Code\\\"; \\\"2. Install Packages\\\"; \\\"3. Snapshot\\\"; \\\"4. Restore\\\"\\n  \\n  \\\"1. Create a Project\\\"->\\\"Write Code\\\"\\n  \\\"Write Code\\\"->\\\"2. Install Packages\\\" \\n  \\\"2. Install Packages\\\" -> \\\"Write Code\\\"\\n  \\\"Write Code\\\"->\\\"3. Snapshot\\\"\\n  \\\"3. Snapshot\\\"->\\\"4. Restore\\\"\\n  \\n}      \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Simple Workflow for Reproducible Environments\n\n\n\nrenv::create()\npak::pkg_install(...)\nrenv::snapshot()\nrenv::restore()\nPre-requisite Steps:\n(Administrators) Install each desired version of R.\n(Users) Install the renv package: remotes::install_github('rstudio/renv')\nStep 1: Initalize a Project\nA key to package management is to isolate projects from one another. This allows you to upgrade or add packages for one project without breaking other work. Whether you are in an existing project or starting a new project, use:\n\n\nrenv::init()\n\n\n\nBehind the scenes, renv works by creating a new library. A library stores installed packages.\nStep 2: Install and Use Packages\nWith the project configured, you can now install and use packages. There are three ways to install packages:\nUse pak::pak_install if you’re installing interactively.\nUse remotes::install_* if you’re scripting the install (e.g. in a Docker container).\nUse install.packages as a fall back option.\n\n\n# You can use install.packages\ninstall.packages('ggplot2')\n\n# But we recommend using pak in interactive settings\npak::pkg_install('ggplot2')\n\n# Or use remotes if you're working on an automated script or \n# in a lightweight environment like Docker\nremotes::install_cran('ggplot2')\n\n\n\nUse packages just how you normally would!\n\n\nlibrary(ggplot2)\n\n\n\nStep 3: Snapshot the Environment\nOnce you are ready to share your work, or you are finished with a project, you’ll want to make a record of the current environment.\n\n\nrenv::snapshot()\n\n\n\nThis step creates a new file in your project titled renv.lock. The file contains all the information you need to communicate your project’s dependencies at the moment you call snapshot. The next time you call snapshot, the file will be updated.\nIf you are familiar with version control for your code, we recommend calling snapshot anytime you push or check-in changes to your code. The renv::history and renv::revert commands make it easy to navigate and restore prior versions of the lock file.\nStep 4: Recreate the Environment\nThis step is where the work above pays off! If you need to share your work with others, or need to roll back changes to get back to a working library, cash in by using restore:\n\n\n# open the project, and use\nrenv::restore()\n\n\n\nrenv will recreate the package environment for you, and you’ll be back to working on R code instead of troubleshooting problems!\nWatch a video demo of Snapshot and Restore with renv\n\n\n\n\n\nImplementing the Snapshot Strategy in Production\nIn some organizations, you may only want to worry about recording project dependencies when a project is ready for production. Generating a manifest of dependencies can be the first step in a deployment hand-off between a development environment and a production deployment. Learn more about snapshotting for production.\nIf you are using RStudio Connect then the snapshot strategy is automatically applied when content is deployed.\nCommon Challenges and Resolutions:\nVersions of R\nTo ensure the library is restorable, you’ll need to record and make available the same version of R used during development. The renv package automatically records the version of R used by a project. We recommend having multiple versions of R available, so that users can pick the version of R and then restore. This approach is also an effective way to test if a project is ready to upgrade to a new version of R.\nNon-Current CRAN Packages\nOften, by the time a project is restored, some of the packages in use may have been updated on CRAN. For example:\nOn January 1st, a project manifest is committed that records ISLR version 1.0 as a dependency.\nOn February 1st, the ISLR package is upgraded to 1.1.\nOn March 1st, a user wishes to restore the environment.\nIn this case, it is critical that version 1.0 of ISLR is used in the restored environment. To make this happen, the older version of the package needs to be accessed and installed. Luckily, this is possible using a repository’s archive. Internal repositories used to support the snapshot strategy must record archived versions. RStudio Package Manager is an easy way to ensure your internal repository handles this case appropriately.\nInternal Packages\nIf your package is publicly available, tools like renv will work automatically. If you wish to use the snapshot strategy along with internal packages (packages that are not publicly available on CRAN nor in a public Git repository), it is easiest to store and source those internal packages in a CRAN-like repository. Follow these steps:\nRelease the internal package to the CRAN-like repository\nInstall and use the package in the project, installing from the repository\nRecord the project dependencies\nRestore the project by accessing the appropriate version of the package from the CRAN-like repository\nIt is critical that older versions of the internal package are appropriately stored in the repository’s archive. The easiest way to create a correct internal repository, distribute internal packages, and support the snapshot strategy is using RStudio Package Manager\nMulti-Lingual Projects (Python)\nIf your project uses more than R, you’ll need to capture the project’s other dependencies as well. A common scenario is a reticulated project that uses Python and R. In this case, one option is to combine renv with a Python package management tool like virtualenv:\nUse renv as described previously to manage R packages\nUse a virutalenv to isolate project Python dependencies\nRecord the state of the virtualenv using pip freeze > requirements.txt\nOn restore, recreate the Python virtualenv and then use renv::restore()\nTo automate some of these steps, take advantage of the renv::use_python function.\nPerformance\nA common challenge in the snapshot and restore approach is that each project relies on an isolated library. Naively, this would mean each project library would start empty and users would have to re-install their desired packages. In practice, this naive approach is slow - especially on systems where packages must be compiled.\nTo solve this problem, implementations of the snapshot and restore strategy should rely on a package cache or a repository that serves binaries for the operating systems in-use. By default, renv creates a cache for each user. This means if two projects rely on ggplot2 version 3.1.0, the user will only need to install ggplot2 3.1.0 once. A repository that serves binaries accomplishes the same result, effectively caching installed packages for all users!\nOften restoring a project on a different computer or a new system can take time because the necessary packages may not be cached. This challenge is especially prevalent if the project uses non-current CRAN packages, because these packages do not usually have a binary version available in a repository.\nDocker\nUnfortunately, many organizations and platforms assume using Docker will give them the benefits of reproducibility. The good news is that Docker does a great job isolating project dependencies. The bad news is that Docker does not record the versions of project dependencies. Luckily, Docker can be used with the snapshot and restore strategy. For example, say you wanted to use Docker to execute an ETL job:\n\nFROM ubuntu\n...\nRUN git clone https://github.com/me/etl-project.git\nRUN R -e 'renv::restore()' \nCMD <some process>\n\nAdditional Resources:\nLearn more about libraries\nLearn more about repositories\nLearn more about package installation\n\n\n\n",
      "last_modified": "2021-10-28T18:55:26+00:00"
    },
    {
      "path": "upgrades.html",
      "title": "Upgrading Packages",
      "description": "How to Safely Upgrade Packages \n",
      "author": [],
      "contents": "\nUpgrading packages can be a risky affair. Most R users have been in a situation where upgrading a package had uninteded consequences. For example, the upgrade broke part of their code, or upgrading a package for one project accidentally broke the code in another project. Luckily, the strategies for reproducible environments can make package upgrades safe.\nSpecifically, there are two ways reproducible environments support package upgrades:\nThey encourage project isolation.\nThey provide a safety net in case you need to roll back a change.\nThis page describes the Snaphot and Restore strategy with an emphasis on package upgrades. Keep in mind that the other strategies promote safe package upgrades as well. We also present troubleshooting tips for cases where upgrading a package breaks code.\nSnapshot and Restore for Upgrades\nThe first concern for safe upgrades is project isolation. By isolating projects, you can ensure that upgrading the packages for one project won’t break code in other projects. This type of isolation is accomplished by creating per-project libraries. The renv package makes this easy. Inside of your R project, simply use:\n\n\n# inside the project directory\nrenv::init()\n\n# check to see the isolated project library\n.libPaths()\n\n\n\nThe next concern for safely upgrading packages is creating a safety net. If the package upgrade goes poorly, you’ll be able to revert the changes and return to a working state. Again, the renv package makes this process easy.\n\n\n# record the current dependencies in a file called renv.lock\nrenv::snapshot()\n# commit the lockfile alongside your code in version control\n\n\n\nWith an isolated project and a safety net in place, you can now proceed to upgrade or add new packages, while remaining certain the current functional environment is still reproducible. The pak package can be used to install and upgrade packages in an interactive environment:\n\n\n# upgrade packages quickly and safely\npak::pkg_install(\"ggplot2\")\n\n# the interactive prompt shows you exactly what will change\n# helping avoid unintentional or surprising changes\n\n\n\nIf the process of upgrading packages goes poorly, you can roll back the change using the safety net created earlier:\n\n\n# use this function to view the history of your lockfile\nrenv::history()\n\n# if an upgrade goes astray, revert the lockfile\nrenv::revert(commit = \"abc123\")\n\n# and restore the previous environment\nrenv::restore()\n\n\n\nThe safety net provided by the renv package relies on access to older versions of R packages. For public packages, CRAN provides these older versions in the CRAN archive. Organizations can use tools like RStudio Package Manager to make multiple versions of private packages available\nWhat if an upgrade breaks code?\nA common problem after upgrading packages is to hit an error running the library statements in your code. This occurs because package upgrades can leave your project library in an inconsistent state. One fix is to upgrade all of the packages used in your project. It is best to restart the R session prior to performing these upgrades, as loaded packages can often prevent successful upgrades. The Validated and Shared Baseline strategies address this problem by requiring upgrades to the entire repository.\nIf all of your library statements work, but your code still fails to run, it is likely the functions in a package changed. At this point you can roll back your change or take time to investigate and update your code. The first place to look is the package’s News file. For example, this is the ggplot2 News file. A News file will what has changed, and detail what steps a user will should take in order to adapt their code. Focus on the changes listed between the version you were using and latest version - both pieces of information are displayed in the pak install prompt. Normally you can identify the problematic package based on where the error occurs in your code. The itdepends package can also help you identify which functions are in use.\nWatch a video demo of Snapshot and Restore with renv\n\n\n\n\n\n\n\n\n",
      "last_modified": "2021-10-28T18:55:27+00:00"
    },
    {
      "path": "validated.html",
      "title": "Validated",
      "description": "Control Approved Packages\n",
      "author": [],
      "contents": "\n\nContents\nAdmin Steps: Creating the Validated Set\nAdmin Steps: Updating the Validated Set\nUser Steps: Accessing the Validated Set\nUser Steps: Accessing Updates to the Validated Set\n\nThe validated strategy is similar to the shared baseline strategy. The main difference is the validated strategy targets teams wishing to restrict access to a particular set of packages and teams wishing to approve or audit changes to the package environment. This strategy is appropriate if you require:\nlicensing checks\ntests to ensure accurate package methods\nsecurity audits\nPlease refer to the section “package selection” for more ideas on how to arrive at an approved set of packages. Once a set is determined, this strategy ensures users accurately use those packages.\n\nNote: This strategy describes how to manage approved sets of packages, see the validation section for more information on other considerations in validated environments\n\nThe implementation steps1 are divided into two parts:\nSteps taken by the administrator or R user responsible for creating and updating the approved set\nSteps taken by the user wishing to use the approved set\nAdmin Steps: Creating the Validated Set\nWe recommend that an admin organize the validated set of packages into an internal repository. Organizing the packages into a repository, as opposed to a library, has the major benefit of decoupling the approved packages from a specific installed environment. This separation is helpful because it enables the approved packages to be used in different places: desktops, containers, and shared servers.\nCreate a frozen repository containing all of CRAN along with any other packages you might need.2\nCreate a list of desired top-level packages:\nxgboost\nshiny\nGiven the list, identify the package’s dependencies to get the full set of packages:\nrstudio-pm: $ ./bin/rspm add --file-in=list.csv --source=validated --dryrun\nThis action will add the following packages:\n\nName        Version  Path              License                                Needs Compilation Dependency Already Available\nBH          1.69.0-1                   BSL-1.0                                no                true       false\ncrayon      1.3.4                      MIT + file LICENSE                     no                true       false\ndata.table  1.12.0                     MPL-2.0 | file LICENSE                 yes               true       false\ndigest      0.6.18                     GPL (>= 2)                             yes               true       false\nhtmltools   0.3.6                      GPL (>= 2)                             yes               true       false\nhttpuv      1.4.5.1                    GPL (>= 2) | file LICENSE              yes               true       false\njsonlite    1.6                        MIT + file LICENSE                     yes               true       false\nlater       0.8.0                      GPL (>= 2)                             yes               true       false\nlattice     0.20-38                    GPL (>= 2)                             yes               true       false\nlattice     0.20-38  3.5.3/Recommended GPL (>= 2)                             yes               true       false\nlattice     0.20-38  3.6.0/Recommended GPL (>= 2)                             yes               true       false\nmagrittr    1.5                        MIT + file LICENSE                     no                true       false\nMatrix      1.2-15                     GPL (>= 2) | file LICENCE              yes               true       false\nMatrix      1.2-15   3.5.3/Recommended GPL (>= 2) | file LICENCE              yes               true       false\nMatrix      1.2-15   3.6.0/Recommended GPL (>= 2) | file LICENCE              yes               true       false\nmime        0.6                        GPL                                    yes               true       false\npromises    1.0.1                      MIT + file LICENSE                     yes               true       false\nR6          2.4.0                      MIT + file LICENSE                     no                true       false\nRcpp        1.0.0                      GPL (>= 2)                             yes               true       false\nrlang       0.3.1                      GPL-3                                  yes               true       false\nshiny       1.2.0                      GPL-3 | file LICENSE                   no                false      false\nsourcetools 0.1.7                      MIT + file LICENSE                     yes               true       false\nstringi     1.3.1                      file LICENSE                           yes               true       false\nxgboost     0.81.0.1                   Apache License (== 2.0) | file LICENSE yes               false      false\nxtable      1.8-3                      GPL (>= 2)                             no                true       false\n\nTo complete this operation, execute this command without the --dryrun flag. You will need to include the --transaction-id=1506 flag.\n\n\nThis example shows the RStudio Package Manager command and output for this step, but the main idea is to identify the dependencies for xgboost and shiny.\nAt this point, apply any filtering or additional testing to confirm the packages meet your licensing requirements, methodology validation, etc. If a package must be removed, ensure that you remove all upstream dependencies as well. An easy way to do this is to remove packages from your list in step 2, repeating step 3 until the troublesome package is no longer required.\nPlace the approved set of packages in the internal repository.\nAdmin Steps: Updating the Validated Set\nTo add a new package to the approved set, it is critical that you either update all of the packages or add the new package from the original frozen repository created in step 1. Learn more about the danger of partial upgrades here.\nrstudio-pm: $ ./bin/rspm add --packages=plumber --source=validated --dryrun             \nThis action will add the following packages:\n\nName     Version  Path License                   Needs Compilation Dependency Already Available\nBH       1.69.0-1      BSL-1.0                   no                true       true\ncrayon   1.3.4         MIT + file LICENSE        no                true       true\nhttpuv   1.4.5.1       GPL (>= 2) | file LICENSE yes               true       true\njsonlite 1.6           MIT + file LICENSE        yes               true       true\nlater    0.8.0         GPL (>= 2)                yes               true       true\nmagrittr 1.5           MIT + file LICENSE        no                true       true\nplumber  0.4.6         MIT + file LICENSE        no                false      false\npromises 1.0.1         MIT + file LICENSE        yes               true       true\nR6       2.4.0         MIT + file LICENSE        no                true       true\nRcpp     1.0.0         GPL (>= 2)                yes               true       true\nrlang    0.3.1         GPL-3                     yes               true       true\nstringi  1.3.1         file LICENSE              yes               true       true\n\nTo complete this operation, execute this command without the --dryrun flag. You will need to include the --transaction-id=1506 flag.\n\n\nExample of adding plumber to the package set containing xgboost and shiny using RStudio Package Manager\nTo update all of the packages, repeat steps 1-5 above, starting with a new frozen repository in step 1.\nrstudio-pm: $ ./bin/rspm add --packages=plumber --source=validated --dryrun             \nThis action will add the following packages:\n\nName     Version  Path License                   Needs Compilation Dependency Already Available\nBH       1.69.0-1      BSL-1.0                   no                true       true\ncrayon   1.3.4         MIT + file LICENSE        no                true       true\nhttpuv   1.4.5.1       GPL (>= 2) | file LICENSE yes               true       true\njsonlite 1.6           MIT + file LICENSE        yes               true       true\nlater    0.8.0         GPL (>= 2)                yes               true       true\nmagrittr 1.5           MIT + file LICENSE        no                true       true\nplumber  0.4.6         MIT + file LICENSE        no                false      false\npromises 1.0.1         MIT + file LICENSE        yes               true       true\nR6       2.4.0         MIT + file LICENSE        no                true       true\nRcpp     1.0.0         GPL (>= 2)                yes               true       true\nrlang    0.3.1         GPL-3                     yes               true       true\nstringi  1.3.1         file LICENSE              yes               true       true\n\nTo complete this operation, execute this command without the --dryrun flag. You will need to include the --transaction-id=1506 flag.\n\nExample of updating the xgboost and shiny set from December 18th, 2018 to March 3rd, 2019 using RStudio Package Manager.\nUser Steps: Accessing the Validated Set\nThere are three options for accessing the set of validated packages:\nIf you are using a Docker container, add a line to install the available packages from the internal repository:\n\nFROM ubuntu\n...\nRUN R -e 'options(repos = c(CRAN = \"https://r-pkgs.example.com/validated\")); install.packages(available.packages()[,\"Package\"])'\n\nIf you are creating a shared environment for multiple users, then set the repo option in the Rprofile.site to point at the internal repository, and optionally install the available packages. For more details, refer to the shared baseline strategy, replacing the generic frozen repository with your validated internal repository.\n\n# after installing R \n# set the repo option in Rprofile.site\nsudo echo 'options(repos = c(CRAN = \"https://r-pkgs.example.com/validated\"))' > R_HOME/etc/Rprofile.site\n\n# optionally, install the packages\nsudo R_HOME/bin/R -e 'install.packages(available.packages()[,\"Package\"])'\n\nIf you are an individual working on a specific project, you can use the renv package to create an isolated project environment and library associated with the validated package set:\n\n# from within your project directory\nrenv::init()\n\n# update the environment to use the validated set from the internal repository\nrenv::modify() //TODO: Change this!\n\n# install packages like normal\ninstall.packages(...)\n\nUser Steps: Accessing Updates to the Validated Set\nLikewise, there are three options for accessing an update to the set of validated packages:\nIf you are using a Docker container, simply rebuild the image.\nIf you are administering a shared environment for multiple users, create a new R installation from source, and set the repo option in your Rprofile.site. For more details, refer to the shared baseline strategy, replacing the generic frozen repository with your validated internal repository.\nIf you are working on a specific project using renv, first run renv::snapshot() to save the current state, and then run update.packages() from within your project.\n\nThe implementation steps for this strategy rely the most heavily on RStudio Package Manager. While you can accomplish this strategy without a paid product, if you are using R in a validated context it is probably worth the licensing fee to do things the easy, correct way!↩︎\nRStudio Package Manager handles this step automatically↩︎\n",
      "last_modified": "2021-10-28T18:55:28+00:00"
    },
    {
      "path": "validation.html",
      "title": "Validation",
      "description": "Using R for Validated Work\n",
      "author": [],
      "contents": "\n\nContents\nQuick Links\nPackage Characteristics\nCRAN Releases\nTests\nDocumentation\nDownloads\nDependencies\nAuthors\nNews, Releases, and Life Cycle\nLicense Restrictions\n\nRelated Work and Advice\nOrganizing Selected Packages\n\nValidating an environmnent consists of 2 elements:\nConfidently recreating the same environment\nTrusting what is in the environment\nThe first concern, reproducing environments, is covered at length by the different strategies for environment management. The validated strategy is particularly useful for creating sets of approved packages, though other strategies can be used depending on the context.\nThe second concern forces us to answer the question: “Can we trust our environment?”. To trust an environment, we must have confidence that the packages are accurate in their stated purpose. Unfortunately, with 182751 R packages on CRAN, and more added each day, it is impossible to provide a single list of trusted packages. Every organization, or industry, will need to apply their own judgement in determining whether or not to approve a package. This page presents a set of metrics to help organizations make these determinations.\nQuick Links\nNot what you were expecting? Before continuing, here are some quick links to other resources specific to validation in the clinical pharma space:\nBase R Validation Document for FDA\nRStudio Professional Product Validation\nR in Pharma Validation Hub\nValidation Guidance for the tidyverse, tidymodels, r-lib, and gt packages\nValidation Guidance for shiny and rmarkdown\nInstall Verification for RStudio Connect, RStudio Workbench, and RStudio Package Manager\nPackage Characteristics\nThe following heuristics can help you judge whether or not a package is stable and useful. As a general rule of thumb, you can use these characteristics as a checklist when evaluating a package. Like any heuristic, there are exceptions - not all stable and useful packages will have everything.\nCRAN Releases\nThe first question to ask when evaluating a package is: “Is the package on CRAN?”. Before CRAN accepts a package, CRAN runs a thorough set of tests to ensure the package will work with other packages on CRAN. Getting a package through these checks ensures the package is stable, and also indicates the package author is serious and motivated. While not every package on CRAN is perfect, a package on CRAN indicates a minimal level of effort and stability. More information on CRAN tests can be reviewed here.\nMany packages include a badge to quickly indicate their current CRAN status. For example, this is the CRAN status badge for ggplot2:\n\nTests\nIn addition to documentation, a critical indicator that a package is ready for prime time is checking to see whether the package has tests. Normally, package authors include tests in a directory alongside their package code. Tests help authors check their code for accuracy and prevent them from accidentally breaking code.\nMany packages will go a step further and report test coverage. This metric indicates how much of the package code is currently tested. Often package authors will automatically run tests using a continuous integration service and report test status and code coverage through public badges.\nThe following badges show the current test coverage and status for ggplot2:\n \nDocumentation\nA critical indicator of a package’s health and usefulness is the level of documentation. R packages provide documentation in a number of formats:\n-Package READMEs\n-Package Vignettes\n-Function References and Help Files\n-Websites\n-Books\n-Journal Papers\n-Presentations\n-Cheatsheets\nDownloads\nThe number of times a package is downloaded can help you determine how frequently a package is used. Often packages with many downloads are more stable than packages with fewer downloads. However, take care when using this metric - occasionally a package with fewer downloads may be a newer alternative to a package that has many downloads but is nearing end of life.\nRStudio provides download logs for the popular CRAN mirror https://cran.rstudio.com. The easiest way to access these logs is through the cranlogs R package and API, or by visiting this shiny app.\n\n\nlibrary(cranlogs)\nlibrary(lubridate)\nlibrary(ggplot2)\ndownloads <- cranlogs::cran_downloads(\"ggplot2\", from = \"2019-01-01\", to = today()-ddays(1))\nggplot(downloads, aes(date, count)) + \n  geom_line() + \n  theme_minimal() + \n  labs(\n    x = \"Date\", \n    y = \"Daily Downloads\",\n    title = \"ggplot2 Downloads\"\n  )\n\n\n\n\nDependencies\nWhen you consider bringing a package into your environment, it is important to evaluate the package’s dependencies. Evaluating the risk of package dependencies is a complex process. A great place to start is reviewing this talk and the related itdepends tool. A few quick tips:\nPackage dependencies can be viewed in the package’s Description file and come in a few flavors: Suggests, Depends, Imports, and LinkingTo.\nPackage dependencies describe what a package relies on. For example ggplot2 imports rlang, which means ggplot2 requires rlang in order to work. Reverse dependencies indicate the opposite, so ggplot2 is a reverse dependency for rlang.\nYou should understand how package inter-dependencies impact reproducibility.\nIn addition to depending on other R packages, a package can have system requirements. For example, the rJava package requires a Java installation. You can view system dependencies for a package in the Description file, though a more complete listing is available here or in RStudio Package Manager.\nAuthors\nR packages will list the package’s author(s) in the Description file. It can be useful to see the number of authors and their affiliation. For a package on GitHub, it is possible to view the contribution activity. Some packages will include contribution guidelines.\nFor packages developed in a public forum, such as GitHub, it can be useful to review the package’s open issues and pull requests. Are the package authors responsive to questions and feedback? Are issues addressed in a timely manner?\nNews, Releases, and Life Cycle\nAnother indicator of a package’s stability is the package’s release history. For packages on GitHub, this release history is often visible directly. You can also look for the package’s NEWS file.\nUnfortunately, just looking at the number of releases or the date of the last release does not paint the whole picture. Some packages will have lots of recent releases because they are rapidly changing. Other packages might not have had a release for quite some time - is this because the package has been abandoned? Or is it because the package is really stable? Considering the package’s state of life can help answer these questions.\n\n\n\n\nLicense Restrictions\nFinally, when picking a package, you should consider if your organization has any licensing restrictions. Licenses for R packages can be found in their Description file, and many R packages include an additional license file. Organizations with strict licensing requirements might consider an internal repository to track and audit license usage.\n\n\nap <- available.packages()\nlicences <-tibble(type = ap[,\"License\"])\nlicences %>% \n  group_by(type) %>% \n  count() %>%\n  arrange(desc(n)) %>% \n  head(10) %>% \n  ggplot() + \n  geom_bar(aes(reorder(type, n), n),stat = \"identity\") +\n  coord_flip() + \n  theme_minimal() + \n  labs(\n    title = \"Top 10 CRAN License Types\",\n    x = 'License Type',\n    y = '# of Packages'\n  )\n\n\n\n\nRelated Work and Advice\nA group of pharmaceutical companies has formed a working group aimed at tackling the question of package validation. Take a look at their preliminary work.\nThe ROpenSci project has created a repository of packages that undergo significant peer review. Additionally, they also sponsor a tool for identifying useful package metrics.\nJulia Silge has written an excellent series of blog posts expanding on the topic of package selection.\nFinally, CRAN itself maintains a series of Task Views, and many websites provide options for searching CRAN, such as METACRAN.\nOrganizing Selected Packages\nIf you work in an organization, you may want an easy way to harness tribal knowledge about packages that meet your team’s requirements - or packages that have proven useful time and time again. An easy way to share useful sets of packages is through an internal repository which can be created using RStudio Package Manager. Internal repositories also provide an easy way to track package downloads, making it possible to see what packages are actually used by your team!\n\nRun on 2021-10-28↩︎\n",
      "last_modified": "2021-10-28T18:55:33+00:00"
    }
  ],
  "collections": []
}

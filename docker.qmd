---
title: "Environment Management with Docker"
execute:
  echo: false
  warning: false
---

Docker is a large topic. This site focuses on how Docker relates to reproducible
environments, specifically environments for R. R users and admins should be
familiar with four key concepts: Dockerfiles, Images, Registries, and
Containers. Then they should focus on the layers required in an image for R.

## Docker 101 for Data Scientists

Computing in containers can be compared to brewing and drinking a beer. You
start with a recipe that describes all the ingredients you'll need. From the
recipe, you make a batch of the beer. The batch is stored, ready for use.
Finally, on specific occasions, you can pour a glass of beer and drink it.

In Docker, we have:

1. **Dockerfile** - Describes the steps needed to create an environment. This is the recipe.
2. **Image** - When you execute the steps in a Dockerfile, you _build_ the Dockerfile into an image which contains the environment you described. This is the batch of beer.
3. **Registry** - Stores built images, so that others can use them. This is akin to a liquor store.
4. **Container** - At a specific moment, you can _start_ a container from the image, which amounts to running a process in the built environment. This is drinking a pint from the batch of beer. 



```{r}
#| echo: false
library(DiagrammeR)
grViz("
  digraph repos {
  graph [layout = dot
         rankdir = LR]
  node[shape = box]
  Dockerfile Image Container
  
  node[shape = box, style=filled, color=grey]
  Registry 
  
  Image -> Registry
  Registry -> Image
  
  Dockerfile -> Image
  Image -> Container
}      
")
```

**Docker is powerful because it allows you to create isolated, explicit
environments where specific commands are run.** In our analogy, the benefits are
comparable to a group of friends going to a bar and ordering drinks:

1. You can easily pour many "replicas" of the same beer.
2. The bartender (a server, in computer terms), is decoupled from the beer we want - we don't have to go to the brewer and brew a new beer each time we want a pint.
3. As a result, the same bartender can offer many different types of beers 

For R users and admins, it is important to understand that containers are tied
to a process. This is the key difference in most user's experience between a
container and a virtual machine. For R users, the process that is running can
fall into two buckets:

```{r}
#| fig.cap: "Two Types of Containers for Data Science"
library(gt)
library(dplyr)
library(tidyr)
procs <- data.frame(
  dev = c("Create an analysis in a controlled environment", "RStudio", "IDE Session", "Changes are Saved"),
  prod = c("Run a production model", "R", "R -e shiny::runApp", "Read Only"),
  rowname_col = c("Use Case", "Runtime Entrypoint", "Example Process", "Code & Environment")
  , stringsAsFactors = FALSE
)
  
gt(procs, rowname_col = "rowname_col") %>% 
  cols_label(dev = "Development Session", prod = "Production Runtime")
  
```


## Layers in a Container

A data science container for R will contain six fundamental components:

1. [Base Operating System](docker.qmd#base-operating-system)
2. [System Dependencies](docker.qmd#system-dependencies)
3. [R](docker.qmd#R)
4. [R Packages](docker.qmd#r-packages)
5. [Code](docker.qmd#code)
6. [Data](docker.qmd#data)

Docker images can inherit and build off of one another, allowing these six
components to be layers together to form a complete image that inherits
components from earlier base images.

```{r}
grViz("
 digraph repos {
  graph [layout = dot
         rankdir = BT]
  node[shape = box]
  'Base OS (ubuntu xenial)'; 'System Dependency (libssl)'; 'R Version (3.5.2)'; 'R Packages (xgboost)'; 'Code (report.Rmd)'
  
  node[shape=oval color=grey style=filled]
  'Command \n (R -e rmarkdown::render)'
  
  'Base OS (ubuntu xenial)'->'System Dependency (libssl)'
  'System Dependency (libssl)'->'R Version (3.5.2)'
  'R Version (3.5.2)'->'R Packages (xgboost)'
  'R Packages (xgboost)'->'Code (report.Rmd)'
  'Code (report.Rmd)' -> 'Command \n (R -e rmarkdown::render)'
}         
")
```

One reason Docker is so successful is because the different layers in a
container are cached. In the example above, you can layer with code, without
rebuilding the entire image. Only the steps "above" the code layer are re-run to
create the updated image. The order of layers is very important, because it
impacts the caching involved and the build time of the image.

In addition to caching, Docker images can build off of one another. As an
example, the first 3 layers could be pulled into their own image:

```{r}
grViz("
 digraph repos {
  graph [layout = dot
         rankdir = BT]
  node[shape = box]
  'Base OS (ubuntu xenial)'; 'System Dependency (libssl)'; 'R Version (3.5.2)'; 
  
  node[shape=box color=grey style=filled]
  'Save as new base image \n (company/base-r-image:3.5.2-xenial)'
  
  'Base OS (ubuntu xenial)'->'System Dependency (libssl)'
  'System Dependency (libssl)'->'R Version (3.5.2)'
  'R Version (3.5.2)'->'Save as new base image \n (company/base-r-image:3.5.2-xenial)'
}         
")
```

<aside>
Base images can be saved in a [registry](docker.qmd#dockerhub). The name and tags typically convey information about the image's components and versions.
</aside>

Once the base image is saved, additional images could extend the base image by adding the top layers:

```bash
FROM company/base-r-image:3.5.2-xenial
RUN ...
```

The following sections will cover each component, with a special emphasis on
reproducible environments.

### Base Operating System

Most Docker images start from a base operating system, the most common are
versions of Ubuntu, CentOS, or Debian. These images are normally named by OS and
tagged by release:

```bash
FROM ubuntu:xenial
```

```bash
FROM centos:centos6
```

This layer is the least likely to change, and is normally the "bottom" layer.
For reproducibility, the Dockerfile should tag the desired release of the
operating system.

### System Dependencies

R itself requires a number of system libraries in order to run, and a further
set of system libraries are needed if the image will build R from source. See
this section for [details](r-installation.qmd).

In addition to the requirements for R, R packages often depend on system
libraries. These dependencies can be determined manually by looking at the
package's Description file, or automatically using [RStudio Package
Manager](http://demo.rstudiopm.com/client/#/repos/3/overview) or the [`sysreq` R
package](https://github.com/r-hub/sysreqs).

The Dockerfile steps to install system libraries for R and system libraries for
R packages are best separated. This separation allows you to change the two
lists independently without re-installing everything.

```bash
FROM ubuntu:xenial
# Install system dependencies for R
RUN apt-get update -qq && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y \
    apt-transport-https \
    build-essential \
    curl \
    gfortran \
    libatlas-base-dev \
    libbz2-dev \
    libcairo2 \
    libcurl4-openssl-dev \
    libicu-dev \
    liblzma-dev \
    libpango-1.0-0 \
    libpangocairo-1.0-0 \
    libpcre3-dev \
    libtcl8.6 \
    libtiff5 \
    libtk8.6 \
    libx11-6 \
    libxt6 \
    locales \
    tzdata \
    zlib1g-dev
    
# Install system dependencies for the tidyverse R packages
RUN apt-get install -y \
    make
    libcurl4-openssl-dev
    libssl-dev
    pandoc
    libxml2-dev
```

Normally, system dependencies are reproducible within an operating system
release. In the example above, the versions of each system dependency are not
encoded in the Dockerfile explicitly because apt-get is implicitly providing
versions that are known to be stable   for the xenial Ubuntu release. This
implicit versioning ensures the system dependencies are reproducible.

### R

R can be added to a Docker image in one of three ways:

1. Start from a base image that includes R.

```
FROM rstudio/r-base:3.5-xenial
```

2. Include the commands to [install R within an image]( r-installation.qmd).

```bash
# download a version of R and build from source
ARG R_VERSION=3.5.2
RUN wget https://cdn.rstudio.com/r/ubuntu-1604/pkgs/r-${R_VERSION}_1_amd64.deb
RUN apt-get install -y gdebi-core
RUN gdebi r-${R_VERSION}_1_amd64.deb
```

3. Install R using the system package manager, such as `apt`, `yum`, or `zypper`. See the [details](https://cran.r-project.org/bin/linux/) specific to your desired OS.

```bash
# not the recommended approach
# be sure you request a specific version of R
RUN apt-get install -y \
  r-base=3.4.4-1ubuntu1
```
 
The key in any of the three methods is to be explicit about the version of R you
want included in the image. Similar to R packages, being explicit prevents R
from being updated as a side-effect of rebuilding the image, and instead ensures
R upgrades are intentional.

### R Packages

R packages are handled in a variety of ways. One approach is to include package
installation in the Dockerfile which embeds the packages into the image. A
second approach is to add appropriate R packages when the container is run.

In the former case, it is important to replace the standard `install.packages`
command with a command that will return the same packages, regardless of when
the Dockerfile is built into an image:

```bash
#  install from a versioned repo
RUN R -e 'install.packages(..., repo = "https://rpkgs.company.com/frozen/repo/123")'
```

<aside>
Learn more [here](./shared.html)
</aside>

```bash
# pull in a manifest file and restore it
COPY renv.lock ./
RUN R -e 'renv::restore()'
```

<aside>
Learn more [here](snapshot.qmd)
</aside>

**Using these types of commands ensures the package environment is maintained
explicitly and upgraded intentionally, instead of having R packages upgraded as
a side effect of an image rebuild (which can be hard to predict, due to the
caching involved in image builds).**

A challenge to adding explicit package installation steps into Dockerfiles is
the amount of time it takes to compile the Docker images increases dramatically.
It can also be hard to add the packages' build-time system requirements to the
image. RStudio Package Manager helps resolve both challenges by providing
pre-compiled R packages for different Linux operating systems. Using these
binaries, the package installation step becomes a simple matter of moving a file
into the container, and no compilation is necessary. Learn more
[here](https://blog.rstudio.com/2019/11/07/package-manager-v1-1-no-interruptions/).

The second approach is to add packages into the container at runtime, instead of
including them in the image. Packages added in this manner can be easier to
cache, installed packages can effectively be mounted into the container. Similar
to the first approach, tools like `renv` ensure the version stability. A
downside to this approach is that reproducibility now relies on tracking the
Docker run invocation in addition to the Dockerfile and image. The [`renv`
vignette on Docker](https://rstudio.github.io/renv/articles/docker.html)
provides more details.

```bash
# example docker run command with renv
RENV_PATHS_CACHE_HOST=/opt/local/renv/cache
RENV_PATHS_CACHE_CONTAINER=/renv/cache
docker run --rm \
    -e "RENV_PATHS_CACHE=${RENV_PATHS_CACHE_CONTAINER}" \
    -v "${RENV_PATHS_CACHE_HOST}:${RENV_PATHS_CACHE_CONTAINER}" \
    R --vanilla --slave -e 'renv::activate(); renv::restore()'
```


### Code

Code can be added to an image in three ways:

1. Cloning a Git repository

```bash
RUN git clone https://git.company.com/jane/project.git
```

2. Mounting the files at run time using [Docker volumes](https://docs.docker.com/storage/volumes/)

3. Copying the files into the image with `COPY`

The choice between these three options depends on the intended use of the
container. If the container is being is used to execute production code, then
option 1 is usually the most reliable choice, with option 3 serving as a
fallback. If the container is being used for interactive development, mounting
in files is the most common, because it ensures the changes to the code are
persisted even after the docker container ends.

A related question is whether or not RStudio should be included in the container. The answer depends on the use of the container: whether the container is being used to execute R code or being used to develop R code. In the first case, RStudio is not necessary. In the second case, RStudio should be involved. There are a variety of architectures for using RStudio with Docker, we recommend learning about the [RStudio Launcher](https://solutions.rstudio.com/launcher/overview/).

### Data

A data science container wouldn't be much good without access to data! If the
data is small, follow the suggestions above for [code](./docker.html#code). If
data is large, then don't worry about moving the data into the container.
Instead, focus on connecting the container to the data store. For example, the R
code executed inside the container might [connect to a
database](https://db.rstudio.com), in which case you'll want to ensure the steps
for installing the appropriate database drivers are added to the Dockerfile.

## Example Registries

This final section provides a quick list of references to projects using R and
Docker. These projects can be useful as a way to source images for your own
work, or serve as a catalog of Dockerfiles that can be tweaked, copied, or
extended.

**Keep in mind, each project has a different goal and context. R users new to Docker should take care to understand why the project exists before using a project as the basis for new work.**

### Rocker Project

The [Rocker project](https://www.rocker-project.org/) is a community driven
effort to create a series of self-contained images for R development. These
images can often be used as "virtual machines". The image labels define their
contents, e.g. the `rocker/tidyverse` image includes R and the tidyverse
packages. The tag specifies the specific version of R used in the image. These
images are all based off of the Debian OS.

### R-Hub

[R-Hub](https://hub.docker.com/u/rhub) is a project designed to help R package
authors prepare for [CRAN](https://docs.r-hub.io/#which-platform) package
checks. As part of the project, R-Hub maintains a series of docker images
designed to replicate the environments CRAN uses for testing. The image label
includes key descriptions of the environment, for example,
`rhub/ubuntu-gcc-release` includes the current R release version built with gcc
on Ubuntu.

### RStudio Images 

RStudio provides a series of images designed to act as base layers for those
using [RStudio Launcher](https://solutions.rstudio.com/launcher/overview/).
These images contain minimal dependencies, but include standardized R
installations compatible with package binaries. The label indicates the OS and R
version, e.g `rstudio/r-base:3.4-xenial` is an image with R version 3.4 built on
Ubuntu's xenial release. For more information, visit the [open source
repository](https://github.com/rstudio/r-docker).



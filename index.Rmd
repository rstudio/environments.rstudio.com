---
title: "Reproducible Environments"
description: |
  Manage environments for data science.
site: distill::distill_website
canonical_url: https://environments.rstudio.com/
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DiagrammeR)
```

Great data science work should be reproducible. Being able to repeat experiments
is the foundation of all science. Reproducing work is also critical for business
applications: scheduled reporting, team collaboration, project validation. 

The purpose of this site is to help you understand the key [**use
cases**](./index.html#use-cases) for reproducible environments, the
[**strategies**](./index.html#strategies) you can use to create them, and the
[**tools**](./index.html#tools) you'll need to master.

While everyone should have a plan for reproducible environments, here are a few signs to suggest environment management has gone wrong:

- Code that used to run no longer runs, even though the code has not changed.
- You are afraid to upgrade or install a new package, because it might break your code or someone else's.
- Typing `install.packages` in your environment doesn't do anything, or doesn't do the *right* thing.


If you're an individual data scientist, there are two things you should do
**before you continue any further** with environment management: [learn about
RStudio Projects](https://r4ds.had.co.nz/workflow-projects.html#rstudio-projects) and
[use version control](https://happygitwithr.com/).

If you prefer videos to reading, checkout [this webinar](https://resources.rstudio.com/webinars/time-travel-r).

## Use Cases

Environment management takes work. Here are some cases where the reward is worth the effort:

- When you are working on a long-term project, and need to [safely upgrade packages](./upgrades.html).  
- In cases where you and your team [need to collaborate](./collaborate.html) on the same project, using a common source of truth.
- If you need to [validate](./validation.html) and control the packages you're using.
- When you are ready to [deploy a data product to production](./deploy.html), such as a Shiny app, R Markdown document, or plumber API.

## Strategies

Use cases provide the "why" for reproducible environments, but not the "how". There are a variety of strategies for creating reproducible environments. It is important to recognize that not everyone needs the same approach to reproducibility. If you're a student reporting an error to your professor, capturing your `sessionInfo()` may be all you need. In contrast, a statistician working on a clinical trial will need a robust framework for recreating their environment. **Reproducibility is not binary!**


```{r spectrum, echo = FALSE, layout="l-page", fig.cap="Strategies for reproducibility fall on a spectrum. One side is not better than the other. Pick based on your goals.", fig.height=5, fig.width=8}
library(ggplot2)
library(tibble)
timeline <- tribble(
  ~x, ~y, 
  0, 1,
  16, 1
)

labels <- tribble(
  ~x, ~y, ~label,
  0, 1.1, "No Strategy",
  4, 1.1, "Awareness",
  8, 1.1, "Shared Baseline",
  12, 1.1, "Record & Restore",
  16, 1.1, "Validated",
)

details <- tribble(
  ~x, ~y, ~label,
  0, 0.9, "scary upgrades \n no sharing \n old stuff is broken",
  4, 0.9, "reprex \n sessioninfo()", 
  8, 0.9, "site library \n frozen repo",
  12, 0.9, "renv",
  16, 0.9, "internal repo \ncustom tests"
)


ggplot() + 
  geom_path(data = timeline, aes(x,y),  color = "black") + 
  geom_label(data = labels, aes(x,y,label=label)) + 
  geom_text(data = details, aes(x,y,label=label)) + 
  theme_minimal() + 
  scale_x_continuous(breaks = NULL, limits = c(-2,17)) + 
  scale_y_continuous(breaks = NULL, limits = c(0.5, 1.5)) + 
  labs(
    title = NULL,
    x = NULL,
    y = NULL
  )

```

There are three main strategies covered in this site.

1. The [Snapshot and Restore](./snapshot.html) strategy is used when individual data scientists are responsible for managing a project and have full access to install packages. The strategy uses tools like [renv](https://rstudio.github.io/renv)^[renv is packrat 2.0] to record a project's dependencies and restore them. 

2. The [Shared Baseline](./shared.html) strategy helps administrators coordinate the work of many data scientists by providing common sets of packages to use across projects. The key to this strategy is determining a consistent set of packages that work together.

3. The [Validated](./validated.html) strategy is used when packages must be controlled and meet specific organization standards.

The [strategy map](./reproduce.html) will help you pick between the different strategies.


## Tools

Data science environments are built from a common set of tools.

```{r fig.cap="Components of an Environment", echo=FALSE}
grViz(
  "digraph env {

 graph [layout = dot
        rankdir = BT]
 node [shape = box]
 'Operating System'
 
 node [shape = oval]
 'R Installation'; 'System Libraries'; 'Python Installation'; 'virtualenv'; 'Project Library'
 
 node [shape = egg]
 User
 
 'Operating System' -> 'Python Installation'
 'Operating System' -> 'System Libraries'
 'Operating System' -> 'R Installation'
 'R Installation' -> 'Project Library'
 'System Libraries' -> 'Project Library'
 'System Libraries' -> 'virtualenv'
 virtualenv -> User
 'Project Library' -> User
 'Python Installation' -> virtualenv
}
")

# 
# nodes <- create_node_df(
#   n = 7,
#   type = "a",
#   label = c(
#     "Operating System",
#     "R Installation", 
#     "System Libraries", 
#     "Python Installation",
#     "virtualenv", 
#     "Project Library",
#     "User"
#   ), 
#   shape = c("box", rep("oval", 5), "egg"), 
#   fillcolor = rep("white", 7)
# )
# 
# edges <- create_edge_df(
#   from = c(rep(1, 3), 2, rep(3, 2), 5, 6, 4),
#   to = c(4, 3, 2, 6, 6, 5, 7, 7, 5)
# )
# 
# create_graph(
#   nodes_df = nodes, 
#   edges_df = edges, 
#   attr_theme = "bt"
# ) %>%
#   add_global_graph_attrs("fixedsize", "false", "node") %>%
#   render_graph()

```

If you use a shared server, some elements might be shared amongst projects and
some elements might exist more than once; e.g. your server might have multiple
versions of R installed. If your organization uses Docker containers, you might
have a base image with some of these components, and runtime installation of
others. Understanding these tools will help you create reproducible environments.

- **R Packages** Managing and recording R packages makes up the bulk of this website. Specifically learn about [repositories](./repositories.html), [installing packages](./installation.html), and [managing libraries](./libraries).

- **R Installation** Packages like `renv` will normally document the version of R used by the project. On shared servers, it is common to install multiple versions of R. Organizations using Docker will typically include R in a base image. Learn more [best practices for R installations](./R-installation.html).

- **Other Languages** Often data science projects are multi-lingual. Combining R and Python is the most common use case, and tools like `renv` have affordances for recording [Python](./python.html) dependencies.

- **System Dependencies** R, Python, and their packages can depend on underlying software that needs to be installed on the system. For example, the `xml2` R package depends on the `libxml` system package. Learn more about how [system dependencies are documented and managed](./installation.html#system-dependencies).

- **Operating System** Operating system configurations can be documented with tools like Docker or through Infrastructure-as-code solutions like Chef and Puppet. Often this step is managed outside of the data science team. Learn more about [best practices for Docker](./docker.html).
